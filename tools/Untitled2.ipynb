{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a919a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clue = '/home/t-yaqingwang/Projects/Few-shot-Learning/data/clue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af948080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ust = '/home/t-yaqingwang/Projects/Few-shot-Learning/data/ust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = mpqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0014aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/t-yaqingwang/Projects/Few-shot-Learning/data/clue/mpqa/10-1/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9ed27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset utils for different data settings for GLUE.\"\"\"\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from filelock import FileLock\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "import transformers\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from transformers import DataProcessor, InputExample\n",
    "from transformers.data.processors.glue import *\n",
    "from transformers.data.metrics import glue_compute_metrics\n",
    "import dataclasses\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Optional, Union\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MrpcProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MRPC data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"un_train.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[3]\n",
    "            text_b = line[4]\n",
    "            label = line[0]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class MnliProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_large_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train_large.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train_large.tsv\")), \"train_large\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"un_train.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev_matched.tsv\")), \"dev_matched\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test_matched.tsv\")), \"test_matched\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "    def get_mappings(self):\n",
    "        return {'contradiction': 'No', 'entailment': 'Yes', 'neutral': 'Maybe'}\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[8].lower()\n",
    "            text_b = line[9].lower()\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class MnliMismatchedProcessor(MnliProcessor):\n",
    "    \"\"\"Processor for the MultiNLI Mismatched data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev_mismatched.tsv\")), \"dev_mismatched\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test_mismatched.tsv\")), \"test_mismatched\")\n",
    "\n",
    "\n",
    "class CLUE_MnliProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_clue_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_large_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train_large.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train_large.tsv\")), \"train_large\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"un_train.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "      \n",
    "        return self._create_clue_examples(self._read_tsv(os.path.join(data_dir, \"dev_matched.tsv\")), \"dev_matched\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test_matched.tsv\")), \"test_matched\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "\n",
    "    def get_mappings(self):\n",
    "        return {'contradiction': 'No', 'entailment': 'Yes', 'neutral': 'Maybe'}\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "\n",
    "            text_a = line[8].lower()\n",
    "            text_b = line[9].lower()\n",
    "          \n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "    def _create_clue_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[-3].lower()\n",
    "            text_b = line[-2].lower()\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "\n",
    "class CLUE_MnliMismatchedProcessor(CLUE_MnliProcessor):\n",
    "    \"\"\"Processor for the MultiNLI Mismatched data set (GLUE version).\"\"\"\n",
    "\n",
    "    def _create_clue_test_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1].lower()\n",
    "            text_b = line[2].lower()\n",
    "            label = line[4]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test_mismatched.tsv\")), \"test_mismatched\")\n",
    "\n",
    "\n",
    "\n",
    "class CLUE_MnliClueProcessor(CLUE_MnliProcessor):\n",
    "    \"\"\"Processor for the MultiNLI Mismatched data set (GLUE version).\"\"\"\n",
    "\n",
    "    def _create_clue_test_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1].lower()\n",
    "            text_b = line[2].lower()\n",
    "            label = line[4]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_clue_test_examples(self._read_tsv(os.path.join(data_dir, \"test_clue.tsv\")), \"test_mismatched\")\n",
    "\n",
    "\n",
    "class SnliProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[7]\n",
    "            text_b = line[8]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class ColaProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the CoLA data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n",
    "            None,\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        test_mode = set_type == \"test\"\n",
    "        text_index = 3\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[text_index]\n",
    "            label = line[1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class Sst2Processor(DataProcessor):\n",
    "    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n",
    "            None,\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        text_index = 0\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[text_index]\n",
    "            label = line[1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "\n",
    "class CLUE_Sst2Processor(DataProcessor):\n",
    "    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n",
    "            None,\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_CLUE_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_CLUE_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        text_index = 0\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[text_index]\n",
    "            label = line[1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "\n",
    "    def _create_CLUE_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[-2]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class CLUE_Sst2ClueProcessor(CLUE_Sst2Processor):\n",
    "    \"\"\"Processor for the MultiNLI Mismatched data set (GLUE version).\"\"\"\n",
    "\n",
    "    def _create_CLUE_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[-2]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_CLUE_examples(self._read_tsv(os.path.join(data_dir, \"test_clue.tsv\")), \"test_clue\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class StsbProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the STS-B data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [None]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[7]\n",
    "            text_b = line[8]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class QqpProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the QQP data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"question1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"question2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        test_mode = set_type == \"test\"\n",
    "        q1_index = 3\n",
    "        q2_index = 4\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            try:\n",
    "                text_a = line[q1_index]\n",
    "                text_b = line[q2_index]\n",
    "                label = line[5]\n",
    "            except IndexError:\n",
    "                continue\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class CLUE_QqpProcessor(QqpProcessor):\n",
    "    \"\"\"Processor for the QQP data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"question1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"question2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test_clue.tsv\")), \"test-clue\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        test_mode = set_type == \"test\"\n",
    "        q1_index = 3\n",
    "        q2_index = 4\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            try:\n",
    "                text_a = line[q1_index]\n",
    "                text_b = line[q2_index]\n",
    "                label = line[5]\n",
    "            except IndexError:\n",
    "                continue\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class QnliProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the QNLI data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"question\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"entailment\", \"not_entailment\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1]\n",
    "            text_b = line[2]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class RteProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the RTE data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"entailment\", \"not_entailment\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1]\n",
    "            text_b = line[2]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "class CLUE_RteProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the RTE data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"entailment\", \"not_entailment\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1]\n",
    "            text_b = line[2]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "\n",
    "class CLUE_RteClueProcessor(CLUE_RteProcessor):\n",
    "    \"\"\"Processor for the MultiNLI Mismatched data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test_clue.tsv\")), \"test_clue\")\n",
    "\n",
    "\n",
    "class WnliProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the WNLI data set (GLUE version).\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"un_train.tsv\")), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1]\n",
    "            text_b = line[2]\n",
    "            label = line[-1]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "\n",
    "class TextClassificationProcessor(DataProcessor):\n",
    "    \"\"\"\n",
    "    Data processor for text classification datasets (mr, sst-5, subj, trec, cr, mpqa).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task_name):\n",
    "        self.task_name = task_name \n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n",
    "            None,\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "  \n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(pd.read_csv(os.path.join(data_dir, \"train.csv\"), header=None).values.tolist(), \"train\")\n",
    "\n",
    "    def get_un_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(pd.read_csv(os.path.join(data_dir, \"un_train.csv\"), header=None).values.tolist(), \"un_train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(pd.read_csv(os.path.join(data_dir, \"dev.csv\"), header=None).values.tolist(), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(pd.read_csv(os.path.join(data_dir, \"test.csv\"), header=None).values.tolist(), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        if self.task_name == \"mr\":\n",
    "            return list(range(2))\n",
    "        elif self.task_name == \"sst-5\":\n",
    "            return list(range(5))\n",
    "        elif self.task_name == \"subj\":\n",
    "            return list(range(2))\n",
    "        elif self.task_name == \"trec\":\n",
    "            return list(range(6))\n",
    "        elif self.task_name == \"cr\":\n",
    "            return list(range(2))\n",
    "        elif self.task_name == \"mpqa\":\n",
    "            return list(range(2))\n",
    "        else:\n",
    "            raise Exception(\"task_name not supported.\")\n",
    "        \n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            if self.task_name == \"ag_news\":\n",
    "                examples.append(InputExample(guid=guid, text_a=line[1] + '. ' + line[2], short_text=line[1] + \".\", label=line[0]))\n",
    "            elif self.task_name == \"yelp_review_full\":\n",
    "                examples.append(InputExample(guid=guid, text_a=line[1], short_text=line[1], label=line[0]))\n",
    "            elif self.task_name == \"yahoo_answers\":\n",
    "                text = line[1]\n",
    "                if not pd.isna(line[2]):\n",
    "                    text += ' ' + line[2]\n",
    "                if not pd.isna(line[3]):\n",
    "                    text += ' ' + line[3]\n",
    "                examples.append(InputExample(guid=guid, text_a=text, short_text=line[1], label=line[0])) \n",
    "            elif self.task_name in ['mr', 'sst-5', 'subj', 'trec', 'cr', 'mpqa']:\n",
    "                examples.append(InputExample(guid=guid, text_a=line[1], label=line[0]))\n",
    "            else:\n",
    "                raise Exception(\"Task_name not supported.\")\n",
    "\n",
    "        return examples\n",
    "\n",
    "\n",
    "class CLUE_TextClassificationProcessor(TextClassificationProcessor):\n",
    "    \"\"\"\n",
    "    Data processor for text classification datasets (mr, sst-5, subj, trec, cr, mpqa).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(pd.read_csv(os.path.join(data_dir, \"test_clue.csv\"), header=None).values.tolist(),\n",
    "                                     \"test-clue\")\n",
    "\n",
    "\n",
    "def text_classification_metrics(task_name, preds, labels):\n",
    "    return {\"acc\": (preds == labels).mean()}\n",
    "\n",
    "# Add your task to the following mappings\n",
    "\n",
    "processors_mapping = {\n",
    "    \"cola\": ColaProcessor(),\n",
    "    \"mnli\": MnliProcessor(),\n",
    "    \"mnli-mm\": MnliMismatchedProcessor(),\n",
    "    \"mrpc\": MrpcProcessor(),\n",
    "    \"sst-2\": Sst2Processor(),\n",
    "    \"sts-b\": StsbProcessor(),\n",
    "    \"qqp\": QqpProcessor(),\n",
    "    \"qnli\": QnliProcessor(),\n",
    "    \"rte\": RteProcessor(),\n",
    "    \"wnli\": WnliProcessor(),\n",
    "    \"snli\": SnliProcessor(),\n",
    "    \"mr\": TextClassificationProcessor(\"mr\"),\n",
    "    \"sst-5\": TextClassificationProcessor(\"sst-5\"),\n",
    "    \"subj\": TextClassificationProcessor(\"subj\"),\n",
    "    \"trec\": TextClassificationProcessor(\"trec\"),\n",
    "    \"cr\": TextClassificationProcessor(\"cr\"),\n",
    "    \"mpqa\": TextClassificationProcessor(\"mpqa\")\n",
    "}\n",
    "\n",
    "CLUE_processors_mapping = {\n",
    "    \"cola\": ColaProcessor(),\n",
    "    \"mnli\": CLUE_MnliProcessor(),\n",
    "    \"mnli-clue\": CLUE_MnliClueProcessor(),\n",
    "    \"mnli-mm\": CLUE_MnliMismatchedProcessor(),\n",
    "    \"mrpc\": MrpcProcessor(),\n",
    "    \"sst-2\": CLUE_Sst2Processor(),\n",
    "    \"sst-2-clue\": CLUE_Sst2ClueProcessor(),\n",
    "    \"sts-b\": StsbProcessor(),\n",
    "    \"qqp\": QqpProcessor(),\n",
    "    \"qqp-clue\": CLUE_QqpProcessor(),\n",
    "    \"qnli\": QnliProcessor(),\n",
    "    \"rte\": CLUE_RteProcessor(),\n",
    "    \"rte-clue\": CLUE_RteClueProcessor(),\n",
    "    \"wnli\": WnliProcessor(),\n",
    "    \"snli\": SnliProcessor(),\n",
    "    \"mr\": TextClassificationProcessor(\"mr\"),\n",
    "    \"mr-clue\":  CLUE_TextClassificationProcessor(\"mr\"),\n",
    "    \"sst-5\": TextClassificationProcessor(\"sst-5\"),\n",
    "    \"subj\": TextClassificationProcessor(\"subj\"),\n",
    "    \"subj-clue\": CLUE_TextClassificationProcessor(\"subj\"),\n",
    "    \"trec\": TextClassificationProcessor(\"trec\"),\n",
    "    \"cr\": TextClassificationProcessor(\"cr\"),\n",
    "    \"mpqa\": TextClassificationProcessor(\"mpqa\"),\n",
    "   \"mpqa-clue\": CLUE_TextClassificationProcessor(\"mpqa\")\n",
    "}\n",
    "\n",
    "num_labels_mapping = {\n",
    "    \"cola\": 2,\n",
    "    \"mnli\": 3,\n",
    "    \"mrpc\": 2,\n",
    "    \"sst-2\": 2,\n",
    "    \"sts-b\": 1,\n",
    "    \"qqp\": 2,\n",
    "    \"qnli\": 2,\n",
    "    \"rte\": 2,\n",
    "    \"wnli\": 2,\n",
    "    \"snli\": 3,\n",
    "    \"mr\": 2,\n",
    "    \"sst-5\": 5,\n",
    "    \"subj\": 2,\n",
    "    \"trec\": 6,\n",
    "    \"cr\": 2,\n",
    "    \"mpqa\": 2\n",
    "}\n",
    "\n",
    "output_modes_mapping = {\n",
    "    \"cola\": \"classification\",\n",
    "    \"mnli\": \"classification\",\n",
    "    \"mnli-mm\": \"classification\",\n",
    "    \"mnli-mm-clue\": \"classification\",\n",
    "    \"mrpc\": \"classification\",\n",
    "    \"sst-2\": \"classification\",\n",
    "    \"sst-2-clue\": \"classification\",\n",
    "    \"sts-b\": \"regression\",\n",
    "    \"qqp\": \"classification\",\n",
    "    \"qqp-clue\": \"classification\",\n",
    "    \"qnli\": \"classification\",\n",
    "    \"rte\": \"classification\",\n",
    "     \"rte-clue\": \"classification\",\n",
    "    \"wnli\": \"classification\",\n",
    "    \"snli\": \"classification\",\n",
    "    \"mr\": \"classification\",\n",
    "    \"mr-clue\": \"classification\",\n",
    "    \"sst-5\": \"classification\",\n",
    "    \"subj\": \"classification\",\n",
    "    \"subj-clue\": \"classification\",\n",
    "    \"trec\": \"classification\",\n",
    "    \"cr\": \"classification\",\n",
    "    \"mpqa\": \"classification\",\n",
    "    \"mpqa-clue\": \"classification\"\n",
    "}\n",
    "\n",
    "# Return a function that takes (task_name, preds, labels) as inputs\n",
    "compute_metrics_mapping = {\n",
    "    \"cola\": glue_compute_metrics,\n",
    "    \"mnli\": glue_compute_metrics,\n",
    "    \"mnli-clue\": text_classification_metrics,\n",
    "    \"mnli-mm\": glue_compute_metrics,\n",
    "    \"mrpc\": glue_compute_metrics,\n",
    "    \"sst-2\": glue_compute_metrics,\n",
    "    \"sst-2-clue\": text_classification_metrics,\n",
    "    \"sts-b\": glue_compute_metrics,\n",
    "    \"qqp\": glue_compute_metrics,\n",
    "    \"qqp-clue\": text_classification_metrics,\n",
    "    \"qnli\": glue_compute_metrics,\n",
    "    \"rte\": glue_compute_metrics,\n",
    "    \"rte-clue\": text_classification_metrics,\n",
    "    \"wnli\": glue_compute_metrics,\n",
    "    \"snli\": text_classification_metrics,\n",
    "    \"mr\": text_classification_metrics,\n",
    "    \"mr-clue\": text_classification_metrics,\n",
    "    \"sst-5\": text_classification_metrics,\n",
    "    \"subj\": text_classification_metrics,\n",
    "    \"subj-clue\": text_classification_metrics,\n",
    "    \"trec\": text_classification_metrics,\n",
    "    \"cr\": text_classification_metrics,\n",
    "    \"mpqa\": text_classification_metrics,\n",
    "    \"mpqa-clue\": text_classification_metrics,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# For regression task only: median\n",
    "median_mapping = {\n",
    "    \"sts-b\": 2.5\n",
    "}\n",
    "\n",
    "bound_mapping = {\n",
    "    \"sts-b\": (0, 5)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b09512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for  task_name in [ 'QQP', 'RTE',  'SST-2']:\n",
    "    for k in [10, 20, 30]:\n",
    "        for seed in [1,2,3,4,5]:\n",
    "            data_dir = clue + '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            output_dir = ust+ '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "            try:\n",
    "                os.remove(os.path.join(output_dir, 'test-clue.tsv'))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            processor = CLUE_processors_mapping[task_name.lower()]\n",
    "            for mode in ['train', 'un_train', 'test', 'test_clue']:\n",
    "                if mode == 'train':\n",
    "                    examples = processor.get_train_examples(data_dir)\n",
    "                elif mode == 'un_train':\n",
    "                    examples = processor.get_un_train_examples(data_dir)\n",
    "                elif mode == 'test':\n",
    "                    examples = processor.get_test_examples(data_dir)\n",
    "                elif mode == 'test_clue':\n",
    "                    examples = CLUE_processors_mapping[(task_name+'-clue').lower()].get_test_examples(data_dir)\n",
    "                    \n",
    "                output_file = open(os.path.join(output_dir, mode+'.tsv'), 'w')\n",
    "                for example in examples:\n",
    "                    text_a = example.text_a\n",
    "                    text_b = example.text_b\n",
    "                    label = example.label\n",
    "                    output_file.write(text_a+'\\t')\n",
    "                    if text_b is not None:\n",
    "                        output_file.write(text_b+'\\t')\n",
    "                    output_file.write(label+'\\n')\n",
    "                output_file.close()\n",
    "\n",
    "                    \n",
    "            \n",
    "        \n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fac56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for  task_name in [ 'MNLI']:\n",
    "    for k in [10, 20, 30]:\n",
    "        for seed in [1,2,3,4,5]:\n",
    "            data_dir = clue + '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            output_dir = ust+ '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            processor = CLUE_processors_mapping[task_name.lower()]\n",
    "            for mode in ['train', 'un_train', 'test_matched', 'test_mismatched', 'test_clue']:\n",
    "                if mode == 'train':\n",
    "                    examples = processor.get_train_examples(data_dir)\n",
    "                elif mode == 'un_train':\n",
    "                    examples = processor.get_un_train_examples(data_dir)\n",
    "                elif mode == 'test_machted':\n",
    "                    examples = processor.get_test_examples(data_dir)\n",
    "                elif mode == 'test_mismatched':\n",
    "                    examples = CLUE_processors_mapping['mnli-mm'].get_test_examples(data_dir)\n",
    "                elif mode == 'test_clue':\n",
    "                    examples = CLUE_processors_mapping[(task_name+'-clue').lower()].get_test_examples(data_dir)\n",
    "                    \n",
    "                output_file = open(os.path.join(output_dir, mode+'.tsv'), 'w')\n",
    "                for example in examples:\n",
    "                    text_a = example.text_a\n",
    "                    text_b = example.text_b\n",
    "                    label = example.label\n",
    "                    output_file.write(text_a+'\\t')\n",
    "                    if text_b is not None:\n",
    "                        output_file.write(text_b+'\\t')\n",
    "                    output_file.write(label+'\\n')\n",
    "                output_file.close()\n",
    "\n",
    "                    \n",
    "            \n",
    "        \n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "376174b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for  task_name in [ 'subj', 'mpqa']:\n",
    "    for k in [10, 20, 30]:\n",
    "        for seed in [1,2,3,4,5]:\n",
    "            data_dir = clue + '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            output_dir = ust+ '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "            try:\n",
    "                os.remove(os.path.join(output_dir, 'test-clue.csv'))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            processor = CLUE_processors_mapping[task_name.lower()]\n",
    "            for mode in ['train', 'un_train', 'test', 'test_clue']:\n",
    "                if mode == 'train':\n",
    "                    examples = processor.get_train_examples(data_dir)\n",
    "                elif mode == 'un_train':\n",
    "                    examples = processor.get_un_train_examples(data_dir)\n",
    "                elif mode == 'test':\n",
    "                    examples = processor.get_test_examples(data_dir)\n",
    "                elif mode == 'test_clue':\n",
    "                    examples = CLUE_processors_mapping[(task_name+'-clue').lower()].get_test_examples(data_dir)\n",
    "                output_file = open(os.path.join(output_dir, mode+'.csv'), 'w')\n",
    "                for example in examples:\n",
    "                    text_a = example.text_a\n",
    "                    text_b = example.text_b\n",
    "                    label = example.label\n",
    "                    try:\n",
    "                        output_file.write(text_a+'\\t')\n",
    "                    except:\n",
    "                        continue\n",
    "                        print(example)\n",
    "                    if text_b is not None:\n",
    "                        output_file.write(text_b+'\\t')\n",
    "                    output_file.write(str(label)+'\\n')\n",
    "                output_file.close()\n",
    "\n",
    "                    \n",
    "            \n",
    "        \n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055813ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for  task_name in [ 'MNLI']\n",
    "    for k in [10, 20, 30]:\n",
    "        for seed in [1,2,3,4,5]:\n",
    "            data_dir = clue + '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            output_dir = ust+ '/'+task_name+'/'+str(k)+'-'+str(seed)\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            processor = CLUE_processors_mapping[task_name.lower()]\n",
    "            for mode in ['train', 'un_train', 'test', 'test-clue']:\n",
    "                if mode == 'train':\n",
    "                    examples = processor.get_train_examples(data_dir)\n",
    "                elif mode == 'un_train':\n",
    "                    examples = processor.get_un_train_examples(data_dir)\n",
    "                output_file = open(os.path.join(output_dir, mode+'.tsv'), 'w')\n",
    "                for example in examples:\n",
    "                    text_a = example.text_a\n",
    "                    text_b = example.text_b\n",
    "                    label = example.label\n",
    "                    output_file.write(text_a+'\\t')\n",
    "                    if text_b is not None:\n",
    "                        output_file.write(text_b+'\\t')\n",
    "                    output_file.write(label+'\\n')\n",
    "                output_file.close()\n",
    "\n",
    "                    \n",
    "            \n",
    "        \n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1639f465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for example in train_examples:\n",
    "    print(example.text_b is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054b49a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputExample(guid='train-9', text_a='a cheap scam put together by some cynical creeps at revolution studios and imagine entertainment to make the suckers out there surrender $ 9 and 93 minutes of unrecoverable life . ', text_b=None, label='0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
