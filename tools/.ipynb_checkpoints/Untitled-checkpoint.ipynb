{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6747c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import device\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e72247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca7b1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ea5e2692eec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0margs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_args' is not defined"
     ]
    }
   ],
   "source": [
    "task = 'roberta-base-meta-st'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "for file_name in os.listdir(result_path):\n",
    "    args_dict = get_args(file_name) \n",
    "    \n",
    "    if args is not None:\n",
    "        eval_result = os.path.join(result_path, file_name)\n",
    "        mnli_result_file = 'test_results_mnli.txt'\n",
    "        mnli_mm_result_file = 'test_results_mnli-mm.txt'\n",
    "        try:\n",
    "            args_dict['mnli'] = read_result_file(os.path.join(eval_result, mnli_result_file))\n",
    "            args_dict['mnli_mm'] = read_result_file(os.path.join(eval_result, mnli_mm_result_file))\n",
    "            print(args_dict)\n",
    "            result_list.append(args_dict)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "679e8acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'roberta-large-meta-st', 'seed': '87', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7619969434538971, 'mnli_mm': 0.7747152156224573}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '42', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7529291900152827, 'mnli_mm': 0.7686126932465419}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '87', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7136016301579216, 'mnli_mm': 0.738100081366965}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '100', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7755476311767703, 'mnli_mm': 0.7922091131000814}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '13', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.7048395313295975, 'mnli_mm': 0.7189788445890968}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '21', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7725929699439633, 'mnli_mm': 0.782953620829943}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '13', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7571064696892511, 'mnli_mm': 0.7730878763222132}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '42', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.710952623535405, 'mnli_mm': 0.73413344182262}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '21', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.7803362200713194, 'mnli_mm': 0.7931244914564687}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '87', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7426388181355069, 'mnli_mm': 0.7555939788445891}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '21', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7876719307182883, 'mnli_mm': 0.7938364524003255}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '100', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7291900152827305, 'mnli_mm': 0.7509153783563873}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '13', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7198166072338258, 'mnli_mm': 0.7316924328722538}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '13', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7612837493632195, 'mnli_mm': 0.7759357200976403}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '42', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.713907284768212, 'mnli_mm': 0.7387103336045565}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '42', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7394803871625064, 'mnli_mm': 0.7538649308380797}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '100', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7201222618441161, 'mnli_mm': 0.7361676159479251}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '21', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7606724401426388, 'mnli_mm': 0.7769528071602929}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '13', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7463066734589914, 'mnli_mm': 0.76586655817738}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '87', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7136016301579216, 'mnli_mm': 0.7382017900732303}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '21', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.7710646968925114, 'mnli_mm': 0.7826484947111473}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '42', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7473255221599593, 'mnli_mm': 0.7645443449959316}\n",
      "{'model_name': 'roberta-large-meta-st', 'seed': '100', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.7568008150789608, 'mnli_mm': 0.7780716029292107}\n"
     ]
    }
   ],
   "source": [
    "task = 'roberta-large-meta-st'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "for file_name in os.listdir(result_path):\n",
    "    args_dict = get_args(file_name) \n",
    "    \n",
    "    if args_dict is not None:\n",
    "        eval_result = os.path.join(result_path, file_name)\n",
    "        mnli_result_file = 'test_results_mnli.txt'\n",
    "        mnli_mm_result_file = 'test_results_mnli-mm.txt'\n",
    "        try:\n",
    "            args_dict['mnli'] = read_result_file(os.path.join(eval_result, mnli_result_file))\n",
    "            args_dict['mnli_mm'] = read_result_file(os.path.join(eval_result, mnli_mm_result_file))\n",
    "            print(args_dict)\n",
    "            result_list.append(args_dict)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46046314",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9379926",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e34db00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>seed</th>\n",
       "      <th>meta_batch</th>\n",
       "      <th>gs</th>\n",
       "      <th>finetune</th>\n",
       "      <th>mnli</th>\n",
       "      <th>mnli_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-large-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.752929</td>\n",
       "      <td>0.768613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roberta-large-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.719817</td>\n",
       "      <td>0.731692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>roberta-large-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.720122</td>\n",
       "      <td>0.736168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>roberta-large-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.760672</td>\n",
       "      <td>0.776953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>roberta-large-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.713602</td>\n",
       "      <td>0.738202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name seed meta_batch gs     finetune      mnli   mnli_mm\n",
       "1   roberta-large-meta-st   42          6  1  prompt demo  0.752929  0.768613\n",
       "12  roberta-large-meta-st   13          6  1  prompt demo  0.719817  0.731692\n",
       "16  roberta-large-meta-st  100          6  1  prompt demo  0.720122  0.736168\n",
       "17  roberta-large-meta-st   21          6  1  prompt demo  0.760672  0.776953\n",
       "19  roberta-large-meta-st   87          6  1  prompt demo  0.713602  0.738202"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='6') & (result_frame['finetune']=='prompt demo') & \n",
    "                 (result_frame['gs']=='1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df8cbf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7700976403580146"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='4') & (result_frame['finetune']=='prompt demo') & \n",
    "                 (result_frame['gs']=='1')&(result_frame['seed']='1')]['mnli_mm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4d63b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7093734080489047"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='4') & (result_frame['finetune']=='prompt demo') & \n",
    "                 (result_frame['gs']=='2')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65a883d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400305654610291"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='4') & (result_frame['finetune']=='prompt') & \n",
    "                 (result_frame['gs']=='1')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60c0a8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753661513425549"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='6') & (result_frame['finetune']=='prompt') & \n",
    "                 (result_frame['gs']=='1')]['mnli_mm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f4ab342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6234335201222618, 'mnli_mm': 0.6429007323026851}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.5899133978604177, 'mnli_mm': 0.6082180634662328}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6461538461538462, 'mnli_mm': 0.6673108218063466}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6471726948548141, 'mnli_mm': 0.6636493083807974}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6382068262862964, 'mnli_mm': 0.6570382424735557}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.677330616403464, 'mnli_mm': 0.6983319772172498}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6436067244014264, 'mnli_mm': 0.6620219690805533}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6144676515537443, 'mnli_mm': 0.6404597233523189}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6151808456444218, 'mnli_mm': 0.6315093572009765}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6571574121242996, 'mnli_mm': 0.6714808787632222}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6179317371370352, 'mnli_mm': 0.6373067534580961}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6776362710137545, 'mnli_mm': 0.6923311635475997}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6404482934284259, 'mnli_mm': 0.6672091131000814}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6256749872643912, 'mnli_mm': 0.6357811228641171}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6417727967396841, 'mnli_mm': 0.6684296175752644}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6421803362200713, 'mnli_mm': 0.6501220504475184}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6015282730514518, 'mnli_mm': 0.6169650122050447}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6163015792154865, 'mnli_mm': 0.6344589096826688}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.5627101375445747, 'mnli_mm': 0.5914361269324654}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6818135506877229, 'mnli_mm': 0.700366151342555}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6425878757004585, 'mnli_mm': 0.6612082994304312}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6740703005603668, 'mnli_mm': 0.6880593978844589}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.678349465104432, 'mnli_mm': 0.6899918633034988}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6298522669383596, 'mnli_mm': 0.6353742880390562}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6882322975038206, 'mnli_mm': 0.7026037428803905}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6094752929190015, 'mnli_mm': 0.6419853539462979}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6512480896586856, 'mnli_mm': 0.6705655004068348}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6260825267447784, 'mnli_mm': 0.6476810414971521}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6913907284768211, 'mnli_mm': 0.7092148087876322}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6516556291390728, 'mnli_mm': 0.669039869812856}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6728476821192053, 'mnli_mm': 0.6962978030919447}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '6', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6453387671930718, 'mnli_mm': 0.6624288039056143}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6653082017320427, 'mnli_mm': 0.6879576891781937}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '21', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt demo', 'mnli': 0.6516556291390728, 'mnli_mm': 0.665886899918633}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6705043301069791, 'mnli_mm': 0.693653376729048}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '42', 'meta_batch': '4', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6263881813550688, 'mnli_mm': 0.6476810414971521}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt', 'mnli': 0.6519612837493632, 'mnli_mm': 0.6588689991863304}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '87', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6881304126337239, 'mnli_mm': 0.7070789259560618}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '13', 'meta_batch': '6', 'gs': '1', 'finetune': 'prompt', 'mnli': 0.6396332144676515, 'mnli_mm': 0.6494100895036615}\n",
      "{'model_name': 'roberta-base-meta-st', 'seed': '100', 'meta_batch': '4', 'gs': '2', 'finetune': 'prompt demo', 'mnli': 0.6663270504330107, 'mnli_mm': 0.6863303498779495}\n"
     ]
    }
   ],
   "source": [
    "task = 'roberta-base-meta-st'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "for file_name in os.listdir(result_path):\n",
    "    args_dict = get_args(file_name) \n",
    "    \n",
    "    if args_dict is not None:\n",
    "        eval_result = os.path.join(result_path, file_name)\n",
    "        mnli_result_file = 'test_results_mnli.txt'\n",
    "        mnli_mm_result_file = 'test_results_mnli-mm.txt'\n",
    "        try:\n",
    "            args_dict['mnli'] = read_result_file(os.path.join(eval_result, mnli_result_file))\n",
    "            args_dict['mnli_mm'] = read_result_file(os.path.join(eval_result, mnli_mm_result_file))\n",
    "            print(args_dict)\n",
    "            result_list.append(args_dict)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "750f5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d187ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>seed</th>\n",
       "      <th>meta_batch</th>\n",
       "      <th>gs</th>\n",
       "      <th>finetune</th>\n",
       "      <th>mnli</th>\n",
       "      <th>mnli_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.623434</td>\n",
       "      <td>0.642901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.589913</td>\n",
       "      <td>0.608218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.667311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.647173</td>\n",
       "      <td>0.663649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.638207</td>\n",
       "      <td>0.657038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.677331</td>\n",
       "      <td>0.698332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.643607</td>\n",
       "      <td>0.662022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.614468</td>\n",
       "      <td>0.640460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.615181</td>\n",
       "      <td>0.631509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.657157</td>\n",
       "      <td>0.671481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.617932</td>\n",
       "      <td>0.637307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.677636</td>\n",
       "      <td>0.692331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.640448</td>\n",
       "      <td>0.667209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.625675</td>\n",
       "      <td>0.635781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.641773</td>\n",
       "      <td>0.668430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.642180</td>\n",
       "      <td>0.650122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.601528</td>\n",
       "      <td>0.616965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.616302</td>\n",
       "      <td>0.634459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.562710</td>\n",
       "      <td>0.591436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.681814</td>\n",
       "      <td>0.700366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.642588</td>\n",
       "      <td>0.661208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.674070</td>\n",
       "      <td>0.688059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.678349</td>\n",
       "      <td>0.689992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.629852</td>\n",
       "      <td>0.635374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.688232</td>\n",
       "      <td>0.702604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.609475</td>\n",
       "      <td>0.641985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.651248</td>\n",
       "      <td>0.670566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.626083</td>\n",
       "      <td>0.647681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.691391</td>\n",
       "      <td>0.709215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.651656</td>\n",
       "      <td>0.669040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.672848</td>\n",
       "      <td>0.696298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.645339</td>\n",
       "      <td>0.662429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.665308</td>\n",
       "      <td>0.687958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.651656</td>\n",
       "      <td>0.665887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.670504</td>\n",
       "      <td>0.693653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.626388</td>\n",
       "      <td>0.647681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.651961</td>\n",
       "      <td>0.658869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.688130</td>\n",
       "      <td>0.707079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>prompt</td>\n",
       "      <td>0.639633</td>\n",
       "      <td>0.649410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>roberta-base-meta-st</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>prompt demo</td>\n",
       "      <td>0.666327</td>\n",
       "      <td>0.686330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name seed meta_batch gs     finetune      mnli   mnli_mm\n",
       "0   roberta-base-meta-st   13          6  2       prompt  0.623434  0.642901\n",
       "1   roberta-base-meta-st   42          4  2  prompt demo  0.589913  0.608218\n",
       "2   roberta-base-meta-st   21          4  1       prompt  0.646154  0.667311\n",
       "3   roberta-base-meta-st   21          4  2  prompt demo  0.647173  0.663649\n",
       "4   roberta-base-meta-st   42          4  1  prompt demo  0.638207  0.657038\n",
       "5   roberta-base-meta-st  100          6  2  prompt demo  0.677331  0.698332\n",
       "6   roberta-base-meta-st   42          6  2  prompt demo  0.643607  0.662022\n",
       "7   roberta-base-meta-st   21          6  1       prompt  0.614468  0.640460\n",
       "8   roberta-base-meta-st   13          4  1  prompt demo  0.615181  0.631509\n",
       "9   roberta-base-meta-st  100          6  2       prompt  0.657157  0.671481\n",
       "10  roberta-base-meta-st   42          6  2       prompt  0.617932  0.637307\n",
       "11  roberta-base-meta-st   87          6  1       prompt  0.677636  0.692331\n",
       "12  roberta-base-meta-st   21          6  2       prompt  0.640448  0.667209\n",
       "13  roberta-base-meta-st  100          6  1       prompt  0.625675  0.635781\n",
       "14  roberta-base-meta-st   21          4  2       prompt  0.641773  0.668430\n",
       "15  roberta-base-meta-st   13          6  1  prompt demo  0.642180  0.650122\n",
       "16  roberta-base-meta-st  100          4  1       prompt  0.601528  0.616965\n",
       "17  roberta-base-meta-st   42          6  1       prompt  0.616302  0.634459\n",
       "18  roberta-base-meta-st   13          4  1       prompt  0.562710  0.591436\n",
       "19  roberta-base-meta-st   87          6  2  prompt demo  0.681814  0.700366\n",
       "20  roberta-base-meta-st   13          4  2  prompt demo  0.642588  0.661208\n",
       "21  roberta-base-meta-st  100          6  1  prompt demo  0.674070  0.688059\n",
       "22  roberta-base-meta-st  100          4  1  prompt demo  0.678349  0.689992\n",
       "23  roberta-base-meta-st   13          6  2  prompt demo  0.629852  0.635374\n",
       "24  roberta-base-meta-st   87          6  2       prompt  0.688232  0.702604\n",
       "25  roberta-base-meta-st   42          6  1  prompt demo  0.609475  0.641985\n",
       "26  roberta-base-meta-st  100          4  2       prompt  0.651248  0.670566\n",
       "27  roberta-base-meta-st   42          4  2       prompt  0.626083  0.647681\n",
       "28  roberta-base-meta-st   87          4  1  prompt demo  0.691391  0.709215\n",
       "29  roberta-base-meta-st   21          6  1  prompt demo  0.651656  0.669040\n",
       "30  roberta-base-meta-st   87          4  1       prompt  0.672848  0.696298\n",
       "31  roberta-base-meta-st   21          6  2  prompt demo  0.645339  0.662429\n",
       "32  roberta-base-meta-st   87          6  1  prompt demo  0.665308  0.687958\n",
       "33  roberta-base-meta-st   21          4  1  prompt demo  0.651656  0.665887\n",
       "34  roberta-base-meta-st   87          4  2       prompt  0.670504  0.693653\n",
       "35  roberta-base-meta-st   42          4  1       prompt  0.626388  0.647681\n",
       "36  roberta-base-meta-st   13          4  2       prompt  0.651961  0.658869\n",
       "37  roberta-base-meta-st   87          4  2  prompt demo  0.688130  0.707079\n",
       "38  roberta-base-meta-st   13          6  1       prompt  0.639633  0.649410\n",
       "39  roberta-base-meta-st  100          4  2  prompt demo  0.666327  0.686330"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf70f33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648537952114111"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='6') & (result_frame['finetune']=='prompt demo') & \n",
    "                 (result_frame['gs']=='1')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0f07d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6549566989302088"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='4') & (result_frame['finetune']=='prompt demo') & \n",
    "                 (result_frame['gs']=='1')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c143565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6219256240448294"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='4') & (result_frame['finetune']=='prompt') & \n",
    "                 (result_frame['gs']=='1')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ee8c3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347427407030055"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='6') & (result_frame['finetune']=='prompt') & \n",
    "                 (result_frame['gs']=='1')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbb42ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6454406520631686"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='6') & (result_frame['finetune']=='prompt') & \n",
    "                 (result_frame['gs']=='2')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ef2c4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648313805399898"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='4') & (result_frame['finetune']=='prompt') & \n",
    "                 (result_frame['gs']=='2')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44c0543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6468262862964849"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='4') & (result_frame['finetune']=='prompt demo') & \n",
    "                 (result_frame['gs']=='2')]['mnli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4effdcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655588385124809"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_batch']=='6') & (result_frame['finetune']=='prompt demo') & \n",
    "                 (result_frame['gs']=='2')]['mnli'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4658c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(path):\n",
    "    model_name = path.split('search')[-1].split('_')[1]\n",
    "    split_path = path.split('seed')[-1].split('_')\n",
    "    seed = split_path[1]\n",
    "    meta_batch_size = split_path[2]\n",
    "    gs = split_path[3]\n",
    "    args = {}\n",
    "    try:\n",
    "        finetune = ' '.join(split_path[4].split('-')[:-1])\n",
    "       \n",
    "        args = {'model_name':model_name, 'seed':seed, 'meta_batch':meta_batch_size, 'gs':gs, 'finetune':finetune}\n",
    "    except:\n",
    "        return None\n",
    "  \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6c6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result_file(path):\n",
    "    for i, l in enumerate(open(path)):\n",
    "        if i == 1:\n",
    "            l = l.split()\n",
    "            result = float(l[-1])\n",
    "            return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c025246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log(path, args_list=None):\n",
    "    \n",
    "    log_path = os.path.join(path, 'log')\n",
    "    line = open(log_path).readlines()[0]\n",
    "    line =  re.sub(r'\\<.*\\>', 'None', line)\n",
    "    args = eval(line)\n",
    "    new_args = {}\n",
    "    if args_list is not None:\n",
    "        for arg_para in args_list:\n",
    "            new_args[arg_para] = args[arg_para]\n",
    "    else:\n",
    "        new_args = args\n",
    "    return new_args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983fdc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = ['mnli-mm_test_eval_mnli-mm/acc', 'mnli_test_eval_mnli/acc', \n",
    "             'few_shot_type', 'model_name_or_path', 'gradient_accumulation_steps',\n",
    "             'meta_train_batch_size', 'un_train_batch_size', 'seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "59e79e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6807363710333605, 'mnli_test_eval_mnli/acc': 0.665206316861946, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6680227827502034, 'mnli_test_eval_mnli/acc': 0.6497198166072339, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6491049633848658, 'mnli_test_eval_mnli/acc': 0.6310748853795212, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6635475996745321, 'mnli_test_eval_mnli/acc': 0.6522669383596535, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7039259560618389, 'mnli_test_eval_mnli/acc': 0.6817116658176261, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.649613506916192, 'mnli_test_eval_mnli/acc': 0.6244523688232297, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6012001627339301, 'mnli_test_eval_mnli/acc': 0.5950076413652573, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6769731489015459, 'mnli_test_eval_mnli/acc': 0.6638818135506878, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6494100895036615, 'mnli_test_eval_mnli/acc': 0.6239429444727458, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6595809601301872, 'mnli_test_eval_mnli/acc': 0.6405501782985227, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6989422294548413, 'mnli_test_eval_mnli/acc': 0.6742740703005604, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6295768917819365, 'mnli_test_eval_mnli/acc': 0.6194600101884871, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6714808787632222, 'mnli_test_eval_mnli/acc': 0.6544065206316861, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6157445077298617, 'mnli_test_eval_mnli/acc': 0.6071319409067754, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6872457282343368, 'mnli_test_eval_mnli/acc': 0.669587366276108, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6469690805532954, 'mnli_test_eval_mnli/acc': 0.636984207845135, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6750406834825061, 'mnli_test_eval_mnli/acc': 0.6602139582272033, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7078925956061839, 'mnli_test_eval_mnli/acc': 0.6907794192562404, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6639544344995931, 'mnli_test_eval_mnli/acc': 0.6464595007641365, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6774816924328723, 'mnli_test_eval_mnli/acc': 0.6617422312786552, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6307973962571196, 'mnli_test_eval_mnli/acc': 0.6206826286296485, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6359845402766476, 'mnli_test_eval_mnli/acc': 0.6124299541518085, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.669446704637917, 'mnli_test_eval_mnli/acc': 0.6552215995924605, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6807363710333605, 'mnli_test_eval_mnli/acc': 0.6563423331635252, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6125915378356387, 'mnli_test_eval_mnli/acc': 0.5940906775343862, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6258136696501221, 'mnli_test_eval_mnli/acc': 0.5970453387671931, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6669039869812856, 'mnli_test_eval_mnli/acc': 0.6507386653082017, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.64086655817738, 'mnli_test_eval_mnli/acc': 0.6256749872643912, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7039259560618389, 'mnli_test_eval_mnli/acc': 0.6828323993886908, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.682567127746135, 'mnli_test_eval_mnli/acc': 0.6658176260825267, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6433075671277462, 'mnli_test_eval_mnli/acc': 0.6320937340804891, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6946704637917006, 'mnli_test_eval_mnli/acc': 0.6776362710137545, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6291700569568756, 'mnli_test_eval_mnli/acc': 0.604381049414162, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6551057770545159, 'mnli_test_eval_mnli/acc': 0.6273051451859399, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6851098454027664, 'mnli_test_eval_mnli/acc': 0.6561385634233317, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.637713588283157, 'mnli_test_eval_mnli/acc': 0.6353540499235864, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6667005695687551, 'mnli_test_eval_mnli/acc': 0.655017829852267, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6706672091131001, 'mnli_test_eval_mnli/acc': 0.6533876719307183, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 8, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.688873067534581, 'mnli_test_eval_mnli/acc': 0.6707080998471727, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.657546786004882, 'mnli_test_eval_mnli/acc': 0.6372898624554254, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 21}\n"
     ]
    }
   ],
   "source": [
    "task = 'roberta-base-meta-st-large-unbatch'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b545070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b3d570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6443402954661234"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==6) & (result_frame['few_shot_type']=='prompt-demo') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==8)]['mnli_test_eval_mnli/acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29cb468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577890983188996"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==6) & (result_frame['few_shot_type']=='prompt-demo') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==10)]['mnli_test_eval_mnli/acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25ca474f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436067244014264"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==6) & (result_frame['few_shot_type']=='prompt') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==8)]['mnli_test_eval_mnli/acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "99a1f09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6360468670402446"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==6) & (result_frame['few_shot_type']=='prompt') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==10)]['mnli_test_eval_mnli/acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9343dbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436271013754458"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==4) & (result_frame['few_shot_type']=='prompt') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==10)]['mnli_test_eval_mnli/acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d8f05f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389607743250127"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==4) & (result_frame['few_shot_type']=='prompt-demo') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==10)]['mnli_test_eval_mnli/acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f4cccd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6587060621497708"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==4) & (result_frame['few_shot_type']=='prompt-demo') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==8)]['mnli_test_eval_mnli/acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c98d2a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6763425549227013"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['meta_train_batch_size']==4) & (result_frame['few_shot_type']=='prompt-demo') & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==8)]['mnli-mm_test_eval_mnli-mm/acc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1a65ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6816517493897477, 'mnli_test_eval_mnli/acc': 0.6567498726439124, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6841944670463792, 'mnli_test_eval_mnli/acc': 0.6745797249108507, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5861472742066721, 'mnli_test_eval_mnli/acc': 0.561079979623026, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6717860048820179, 'mnli_test_eval_mnli/acc': 0.6614365766683648, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6398494711147275, 'mnli_test_eval_mnli/acc': 0.6335201222618441, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6107607811228641, 'mnli_test_eval_mnli/acc': 0.5770759042282221, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6942636289666395, 'mnli_test_eval_mnli/acc': 0.6834437086092715, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6762611879576892, 'mnli_test_eval_mnli/acc': 0.6664289353031075, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5135272579332791, 'mnli_test_eval_mnli/acc': 0.484666327050433, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6960943856794142, 'mnli_test_eval_mnli/acc': 0.6959755476311767, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6768714401952807, 'mnli_test_eval_mnli/acc': 0.6653082017320427, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6278478437754271, 'mnli_test_eval_mnli/acc': 0.6231278655119715, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6142188771358829, 'mnli_test_eval_mnli/acc': 0.5895058583800306, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6273393002441009, 'mnli_test_eval_mnli/acc': 0.6042791645440652, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6991456468673718, 'mnli_test_eval_mnli/acc': 0.6852776362710138, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5085435313262815, 'mnli_test_eval_mnli/acc': 0.47885888945491595, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6478844589096827, 'mnli_test_eval_mnli/acc': 0.6319918492103923, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5377339300244101, 'mnli_test_eval_mnli/acc': 0.5256240448293429, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5645850284784377, 'mnli_test_eval_mnli/acc': 0.5506877228731534, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6649715215622457, 'mnli_test_eval_mnli/acc': 0.6421803362200713, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7110455655004069, 'mnli_test_eval_mnli/acc': 0.6954661232806928, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6286615134255492, 'mnli_test_eval_mnli/acc': 0.613143148242486, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7085028478437754, 'mnli_test_eval_mnli/acc': 0.6820173204279164, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6363913751017087, 'mnli_test_eval_mnli/acc': 0.626286296484972, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5058991049633849, 'mnli_test_eval_mnli/acc': 0.47804381049414163, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7048413344182262, 'mnli_test_eval_mnli/acc': 0.6865002547121752, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6142188771358829, 'mnli_test_eval_mnli/acc': 0.5895058583800306, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6604963384865744, 'mnli_test_eval_mnli/acc': 0.6240448293428426, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.686126932465419, 'mnli_test_eval_mnli/acc': 0.6647987773815588, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.673820179007323, 'mnli_test_eval_mnli/acc': 0.6544065206316861, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 42}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6578519121236778, 'mnli_test_eval_mnli/acc': 0.6333163525216505, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 42}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4688771358828316, 'mnli_test_eval_mnli/acc': 0.44431991849210395, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 13}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6769731489015459, 'mnli_test_eval_mnli/acc': 0.6553234844625573, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 6, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7172497965825875, 'mnli_test_eval_mnli/acc': 0.7076923076923077, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6758543531326282, 'mnli_test_eval_mnli/acc': 0.6602139582272033, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 10, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6808380797396257, 'mnli_test_eval_mnli/acc': 0.6517575140091696, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 100}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7145036615134256, 'mnli_test_eval_mnli/acc': 0.7036169128884361, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 6, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6877542717656632, 'mnli_test_eval_mnli/acc': 0.6661232806928171, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 87}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6134052074857608, 'mnli_test_eval_mnli/acc': 0.6050942435048395, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 21}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7106387306753458, 'mnli_test_eval_mnli/acc': 0.6986245542536933, 'few_shot_type': 'prompt-demo', 'model_name_or_path': 'microsoft/deberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 6, 'un_train_batch_size': 10, 'seed': 100}\n"
     ]
    }
   ],
   "source": [
    "task = 'deberta-base-meta-st'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0afd95c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6659072416598861"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_size = 6\n",
    "few_shot = 'prompt-demo'\n",
    "un_train_size = 6\n",
    "\n",
    "\n",
    "\n",
    "result_frame.loc[(result_frame['meta_train_batch_size']==meta_size) & (result_frame['few_shot_type']==few_shot) & \n",
    "                 (result_frame['gradient_accumulation_steps']==1) & (result_frame['un_train_batch_size']==un_train_size) ]['mnli-mm_test_eval_mnli-mm/acc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a616fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = ['mnli-mm_test_eval_mnli-mm/acc', 'mnli_test_eval_mnli/acc', \n",
    "             'few_shot_type', 'model_name_or_path', 'gradient_accumulation_steps',  'prompt_learning_rate',\n",
    "             'meta_train_batch_size', 'un_train_batch_size', 'seed', 'prompt_length', 'prompt_encoder_type', 'learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f4a1741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8886289666395444, 'mnli_test_eval_mnli/acc': 0.8898624554253693, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 1e-05}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8909682668836453, 'mnli_test_eval_mnli/acc': 0.8945491594498217, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "task = 'continuous_prompt_deberta_full_model'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "335b4ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.888629</td>\n",
       "      <td>0.889862</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890968</td>\n",
       "      <td>0.894549</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc few_shot_type  \\\n",
       "0                       0.888629                 0.889862        prompt   \n",
       "1                       0.890968                 0.894549        prompt   \n",
       "\n",
       "        model_name_or_path  gradient_accumulation_steps  \\\n",
       "0  microsoft/deberta-large                            1   \n",
       "1  microsoft/deberta-large                            1   \n",
       "\n",
       "   meta_train_batch_size  un_train_batch_size  seed  prompt_length  \\\n",
       "0                      4                    4   100             80   \n",
       "1                      4                    4   100             80   \n",
       "\n",
       "  prompt_encoder_type  learning_rate  \n",
       "0                 mlp        0.00001  \n",
       "1                None        0.00001  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e025e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6960943856794142, 'mnli_test_eval_mnli/acc': 0.6813041263372389, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.3922904800650936, 'mnli_test_eval_mnli/acc': 0.3811512990320937, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7121643612693247, 'mnli_test_eval_mnli/acc': 0.6935303107488537, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.36391375101708706, 'mnli_test_eval_mnli/acc': 0.36800815078960775, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7187754271765663, 'mnli_test_eval_mnli/acc': 0.7043301069791136, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6911106590724166, 'mnli_test_eval_mnli/acc': 0.6851757514009169, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7590520748576078, 'mnli_test_eval_mnli/acc': 0.7441670911869588, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7193856794141579, 'mnli_test_eval_mnli/acc': 0.7127865511971472, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6174735557363711, 'mnli_test_eval_mnli/acc': 0.6037697401935812, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7536615134255492, 'mnli_test_eval_mnli/acc': 0.741110545084055, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.741659886086249, 'mnli_test_eval_mnli/acc': 0.7264391237901172, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7344385679414158, 'mnli_test_eval_mnli/acc': 0.7212429954151809, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.765052888527258, 'mnli_test_eval_mnli/acc': 0.7534386143657666, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6846013018714402, 'mnli_test_eval_mnli/acc': 0.6654100866021396, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6824654190398698, 'mnli_test_eval_mnli/acc': 0.6640855832908813, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7695280716029292, 'mnli_test_eval_mnli/acc': 0.7597554763117677, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.33624898291293737, 'mnli_test_eval_mnli/acc': 0.33581253183902193, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.73413344182262, 'mnli_test_eval_mnli/acc': 0.7185939887926643, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.3365541090317331, 'mnli_test_eval_mnli/acc': 0.3338767193071829, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6539869812855981, 'mnli_test_eval_mnli/acc': 0.6441161487519104, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.36065907241659884, 'mnli_test_eval_mnli/acc': 0.36383087111563933, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6941619202603743, 'mnli_test_eval_mnli/acc': 0.6741721854304635, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7585435313262815, 'mnli_test_eval_mnli/acc': 0.7458991339786042, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.3334011391375102, 'mnli_test_eval_mnli/acc': 0.3350993377483444, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.33207892595606187, 'mnli_test_eval_mnli/acc': 0.33897096281202244, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6907038242473555, 'mnli_test_eval_mnli/acc': 0.6728476821192053, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.576179820992677, 'mnli_test_eval_mnli/acc': 0.5708609271523178, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7227420667209113, 'mnli_test_eval_mnli/acc': 0.7176770249617932, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6953824247355573, 'mnli_test_eval_mnli/acc': 0.6826286296484972, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7427786818551668, 'mnli_test_eval_mnli/acc': 0.7319409067753438, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7101301871440195, 'mnli_test_eval_mnli/acc': 0.6932246561385634, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.640052888527258, 'mnli_test_eval_mnli/acc': 0.6333163525216505, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.34947111472742065, 'mnli_test_eval_mnli/acc': 0.3443708609271523, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7447111472742066, 'mnli_test_eval_mnli/acc': 0.7343861436576669, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.718673718470301, 'mnli_test_eval_mnli/acc': 0.7118695873662761, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-base', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.35862489829129374, 'mnli_test_eval_mnli/acc': 0.34865002547121754, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7803091944670464, 'mnli_test_eval_mnli/acc': 0.7645440652063169, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "task = 'continuous_prompt_long_length'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a768e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617474</td>\n",
       "      <td>0.603770</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640053</td>\n",
       "      <td>0.633316</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.653987</td>\n",
       "      <td>0.644116</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.719386</td>\n",
       "      <td>0.712787</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.718674</td>\n",
       "      <td>0.711870</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.722742</td>\n",
       "      <td>0.717677</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.690704</td>\n",
       "      <td>0.672848</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.694162</td>\n",
       "      <td>0.674172</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.712164</td>\n",
       "      <td>0.693530</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.682465</td>\n",
       "      <td>0.664086</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.684601</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.710130</td>\n",
       "      <td>0.693225</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.696094</td>\n",
       "      <td>0.681304</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.691111</td>\n",
       "      <td>0.685176</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.695382</td>\n",
       "      <td>0.682629</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.741660</td>\n",
       "      <td>0.726439</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.718775</td>\n",
       "      <td>0.704330</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.734133</td>\n",
       "      <td>0.718594</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.336249</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.360659</td>\n",
       "      <td>0.363831</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.336554</td>\n",
       "      <td>0.333877</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.765053</td>\n",
       "      <td>0.753439</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.758544</td>\n",
       "      <td>0.745899</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.363914</td>\n",
       "      <td>0.368008</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.349471</td>\n",
       "      <td>0.344371</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.744711</td>\n",
       "      <td>0.734386</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.753662</td>\n",
       "      <td>0.741111</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.769528</td>\n",
       "      <td>0.759755</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.333401</td>\n",
       "      <td>0.335099</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.332079</td>\n",
       "      <td>0.338971</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.358625</td>\n",
       "      <td>0.348650</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.759052</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.392290</td>\n",
       "      <td>0.381151</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.742779</td>\n",
       "      <td>0.731941</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.734439</td>\n",
       "      <td>0.721243</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.780309</td>\n",
       "      <td>0.764544</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.576180</td>\n",
       "      <td>0.570861</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc few_shot_type  \\\n",
       "0                        0.617474                 0.603770        prompt   \n",
       "1                        0.640053                 0.633316        prompt   \n",
       "2                        0.653987                 0.644116        prompt   \n",
       "3                        0.719386                 0.712787        prompt   \n",
       "4                        0.718674                 0.711870        prompt   \n",
       "5                        0.722742                 0.717677        prompt   \n",
       "6                        0.690704                 0.672848        prompt   \n",
       "7                        0.694162                 0.674172        prompt   \n",
       "8                        0.712164                 0.693530        prompt   \n",
       "9                        0.682465                 0.664086        prompt   \n",
       "10                       0.684601                 0.665410        prompt   \n",
       "11                       0.710130                 0.693225        prompt   \n",
       "12                       0.696094                 0.681304        prompt   \n",
       "13                       0.691111                 0.685176        prompt   \n",
       "14                       0.695382                 0.682629        prompt   \n",
       "15                       0.741660                 0.726439        prompt   \n",
       "16                       0.718775                 0.704330        prompt   \n",
       "17                       0.734133                 0.718594        prompt   \n",
       "18                       0.336249                 0.335813        prompt   \n",
       "19                       0.360659                 0.363831        prompt   \n",
       "20                       0.336554                 0.333877        prompt   \n",
       "21                       0.765053                 0.753439        prompt   \n",
       "22                       0.758544                 0.745899        prompt   \n",
       "23                       0.363914                 0.368008        prompt   \n",
       "24                       0.349471                 0.344371        prompt   \n",
       "25                       0.744711                 0.734386        prompt   \n",
       "26                       0.753662                 0.741111        prompt   \n",
       "27                       0.769528                 0.759755        prompt   \n",
       "28                       0.333401                 0.335099        prompt   \n",
       "29                       0.332079                 0.338971        prompt   \n",
       "30                       0.358625                 0.348650        prompt   \n",
       "31                       0.759052                 0.744167        prompt   \n",
       "32                       0.392290                 0.381151        prompt   \n",
       "33                       0.742779                 0.731941        prompt   \n",
       "34                       0.734439                 0.721243        prompt   \n",
       "35                       0.780309                 0.764544        prompt   \n",
       "36                       0.576180                 0.570861        prompt   \n",
       "\n",
       "   model_name_or_path  gradient_accumulation_steps  meta_train_batch_size  \\\n",
       "0        roberta-base                            1                      4   \n",
       "1        roberta-base                            1                      4   \n",
       "2        roberta-base                            1                      4   \n",
       "3        roberta-base                            1                      4   \n",
       "4        roberta-base                            1                      4   \n",
       "5        roberta-base                            1                      4   \n",
       "6        roberta-base                            1                      4   \n",
       "7        roberta-base                            1                      4   \n",
       "8        roberta-base                            1                      4   \n",
       "9        roberta-base                            1                      4   \n",
       "10       roberta-base                            1                      4   \n",
       "11       roberta-base                            1                      4   \n",
       "12       roberta-base                            1                      4   \n",
       "13       roberta-base                            1                      4   \n",
       "14       roberta-base                            1                      4   \n",
       "15       roberta-base                            1                      4   \n",
       "16       roberta-base                            1                      4   \n",
       "17       roberta-base                            1                      4   \n",
       "18      roberta-large                            1                      4   \n",
       "19      roberta-large                            1                      4   \n",
       "20      roberta-large                            1                      4   \n",
       "21      roberta-large                            1                      4   \n",
       "22      roberta-large                            1                      4   \n",
       "23      roberta-large                            1                      4   \n",
       "24      roberta-large                            1                      4   \n",
       "25      roberta-large                            1                      4   \n",
       "26      roberta-large                            1                      4   \n",
       "27      roberta-large                            1                      4   \n",
       "28      roberta-large                            1                      4   \n",
       "29      roberta-large                            1                      4   \n",
       "30      roberta-large                            1                      4   \n",
       "31      roberta-large                            1                      4   \n",
       "32      roberta-large                            1                      4   \n",
       "33      roberta-large                            1                      4   \n",
       "34      roberta-large                            1                      4   \n",
       "35      roberta-large                            1                      4   \n",
       "36      roberta-large                            1                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "0                     4   100             40                None   \n",
       "1                     4   100             60                None   \n",
       "2                     4   100             80                None   \n",
       "3                     4   100             40                None   \n",
       "4                     4   100             60                None   \n",
       "5                     4   100             80                None   \n",
       "6                     4   100             40                None   \n",
       "7                     4   100             60                None   \n",
       "8                     4   100             80                None   \n",
       "9                     4   100             40                 mlp   \n",
       "10                    4   100             60                 mlp   \n",
       "11                    4   100             80                 mlp   \n",
       "12                    4   100             40                 mlp   \n",
       "13                    4   100             60                 mlp   \n",
       "14                    4   100             80                 mlp   \n",
       "15                    4   100             40                 mlp   \n",
       "16                    4   100             60                 mlp   \n",
       "17                    4   100             80                 mlp   \n",
       "18                    4   100             40                None   \n",
       "19                    4   100             60                None   \n",
       "20                    4   100             80                None   \n",
       "21                    4   100             40                None   \n",
       "22                    4   100             40                None   \n",
       "23                    4   100             60                None   \n",
       "24                    4   100             80                None   \n",
       "25                    4   100             40                None   \n",
       "26                    4   100             60                None   \n",
       "27                    4   100             80                None   \n",
       "28                    4   100             40                 mlp   \n",
       "29                    4   100             60                 mlp   \n",
       "30                    4   100             80                 mlp   \n",
       "31                    4   100             40                 mlp   \n",
       "32                    4   100             60                 mlp   \n",
       "33                    4   100             80                 mlp   \n",
       "34                    4   100             40                 mlp   \n",
       "35                    4   100             60                 mlp   \n",
       "36                    4   100             80                 mlp   \n",
       "\n",
       "    learning_rate  \n",
       "0           0.100  \n",
       "1           0.100  \n",
       "2           0.100  \n",
       "3           0.010  \n",
       "4           0.010  \n",
       "5           0.010  \n",
       "6           0.001  \n",
       "7           0.001  \n",
       "8           0.001  \n",
       "9           0.100  \n",
       "10          0.100  \n",
       "11          0.100  \n",
       "12          0.010  \n",
       "13          0.010  \n",
       "14          0.010  \n",
       "15          0.001  \n",
       "16          0.001  \n",
       "17          0.001  \n",
       "18          0.100  \n",
       "19          0.100  \n",
       "20          0.100  \n",
       "21          0.010  \n",
       "22          0.010  \n",
       "23          0.010  \n",
       "24          0.010  \n",
       "25          0.001  \n",
       "26          0.001  \n",
       "27          0.001  \n",
       "28          0.100  \n",
       "29          0.100  \n",
       "30          0.100  \n",
       "31          0.010  \n",
       "32          0.010  \n",
       "33          0.010  \n",
       "34          0.001  \n",
       "35          0.001  \n",
       "36          0.001  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61454732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590520748576078"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.01) & (result_frame['prompt_length']==40) & \n",
    "                 (result_frame['prompt_encoder_type']=='mlp')&(result_frame['model_name_or_path']=='roberta-large')]['mnli-mm_test_eval_mnli-mm/acc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "765b0f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6960943856794142"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.01) & (result_frame['prompt_length']==40) & \n",
    "                 (result_frame['prompt_encoder_type']=='mlp')&(result_frame['model_name_or_path']=='roberta-base')]['mnli-mm_test_eval_mnli-mm/acc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ba8f9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7617982099267697"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.01) & (result_frame['prompt_length']==40) & \n",
    "                 (result_frame['prompt_encoder_type']=='None')&(result_frame['model_name_or_path']=='roberta-large')]['mnli-mm_test_eval_mnli-mm/acc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78f24314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.719386</td>\n",
       "      <td>0.712787</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc few_shot_type  \\\n",
       "3                       0.719386                 0.712787        prompt   \n",
       "\n",
       "  model_name_or_path  gradient_accumulation_steps  meta_train_batch_size  \\\n",
       "3       roberta-base                            1                      4   \n",
       "\n",
       "   un_train_batch_size  seed  prompt_length prompt_encoder_type  learning_rate  \n",
       "3                    4   100             40                None           0.01  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.01) & (result_frame['prompt_length']==40) & \n",
    "                 (result_frame['prompt_encoder_type']=='None')&(result_frame['model_name_or_path']=='roberta-base')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6119a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.01\n",
      "0.6985736118186449\n",
      "0.7072314890154597\n",
      "learning_rate 0.001\n",
      "0.698318899643403\n",
      "0.7152664768104149\n",
      "prompt_encoder_type mlp\n",
      "0.699745287824758\n",
      "0.7128593707621372\n",
      "prompt_encoder_type None\n",
      "0.6971472236372899\n",
      "0.7096385950637375\n",
      "prompt_length 40\n",
      "0.6983443708609272\n",
      "0.7119609438567942\n",
      "prompt_length 60\n",
      "0.6938869077941925\n",
      "0.7056804312449145\n",
      "prompt_length 80\n",
      "0.7031074885379521\n",
      "0.7161055736371034\n"
     ]
    }
   ],
   "source": [
    "att_dict = {'learning_rate':[0.01, 0.001], 'prompt_encoder_type':['mlp', 'None'], 'prompt_length' :[40, 60, 80]}\n",
    "for att in att_dict:\n",
    "    for val in att_dict[att]:\n",
    "        print(att, val)\n",
    "        print(result_frame.loc[(result_frame[att]==val)  &  (result_frame['learning_rate'] !=0.1)\n",
    "                 &(result_frame['model_name_or_path']=='roberta-base')]['mnli_test_eval_mnli/acc'].mean())\n",
    "        print(result_frame.loc[(result_frame[att]==val)  &  (result_frame['learning_rate'] !=0.1)\n",
    "                 &(result_frame['model_name_or_path']=='roberta-base')]['mnli-mm_test_eval_mnli-mm/acc'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad5022a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.336554</td>\n",
       "      <td>0.333877</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.349471</td>\n",
       "      <td>0.344371</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.769528</td>\n",
       "      <td>0.759755</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.358625</td>\n",
       "      <td>0.348650</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.742779</td>\n",
       "      <td>0.731941</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.576180</td>\n",
       "      <td>0.570861</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc few_shot_type  \\\n",
       "20                       0.336554                 0.333877        prompt   \n",
       "24                       0.349471                 0.344371        prompt   \n",
       "27                       0.769528                 0.759755        prompt   \n",
       "30                       0.358625                 0.348650        prompt   \n",
       "33                       0.742779                 0.731941        prompt   \n",
       "36                       0.576180                 0.570861        prompt   \n",
       "\n",
       "   model_name_or_path  gradient_accumulation_steps  meta_train_batch_size  \\\n",
       "20      roberta-large                            1                      4   \n",
       "24      roberta-large                            1                      4   \n",
       "27      roberta-large                            1                      4   \n",
       "30      roberta-large                            1                      4   \n",
       "33      roberta-large                            1                      4   \n",
       "36      roberta-large                            1                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "20                    4   100             80                None   \n",
       "24                    4   100             80                None   \n",
       "27                    4   100             80                None   \n",
       "30                    4   100             80                 mlp   \n",
       "33                    4   100             80                 mlp   \n",
       "36                    4   100             80                 mlp   \n",
       "\n",
       "    learning_rate  \n",
       "20          0.100  \n",
       "24          0.010  \n",
       "27          0.001  \n",
       "30          0.100  \n",
       "33          0.010  \n",
       "36          0.001  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result_frame.loc[(result_frame[att]==val) \n",
    "                 &(result_frame['model_name_or_path']=='roberta-large')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "befa5a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73413344182262"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame[att]==val) \n",
    "                 &(result_frame['model_name_or_path']=='roberta-base')]['mnli-mm_test_eval_mnli-mm/acc'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "573a397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.1\n",
      "nan\n",
      "nan\n",
      "learning_rate 0.01\n",
      "0.5812822938650754\n",
      "0.5901575031965594\n",
      "learning_rate 0.001\n",
      "0.7153166921378841\n",
      "0.7264713859506374\n",
      "prompt_encoder_type mlp\n",
      "0.652317880794702\n",
      "0.6641748033631679\n",
      "prompt_encoder_type None\n",
      "0.6352812750163743\n",
      "0.6435545739858188\n",
      "prompt_length 40\n",
      "0.7398267957208355\n",
      "0.752359641985354\n",
      "prompt_length 60\n",
      "0.5637035150280183\n",
      "0.572543734743694\n",
      "prompt_length 80\n",
      "0.6017320427916454\n",
      "0.6094894222945485\n"
     ]
    }
   ],
   "source": [
    "att_dict = {'learning_rate':[0.1, 0.01, 0.001], 'prompt_encoder_type':['mlp', 'None'], 'prompt_length' :[40, 60, 80]}\n",
    "for att in att_dict:\n",
    "    for val in att_dict[att]:\n",
    "        print(att, val)\n",
    "        print(result_frame.loc[(result_frame[att]==val)  &  (result_frame['learning_rate'] !=0.1)\n",
    "                 &(result_frame['model_name_or_path']=='roberta-large')]['mnli_test_eval_mnli/acc'].mean())\n",
    "        print(result_frame.loc[(result_frame[att]==val)  &  (result_frame['learning_rate'] !=0.1)\n",
    "                 &(result_frame['model_name_or_path']=='roberta-large')]['mnli-mm_test_eval_mnli-mm/acc'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d082d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608828315703824"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.01) & (result_frame['prompt_length']==40) \n",
    "                 &(result_frame['model_name_or_path']=='roberta-large')]['mnli-mm_test_eval_mnli-mm/acc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23f74a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3781021155410903"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.01) & (result_frame['prompt_length']==60) \n",
    "                 &(result_frame['model_name_or_path']=='roberta-large')]['mnli-mm_test_eval_mnli-mm/acc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "965df353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.349471</td>\n",
       "      <td>0.344371</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.742779</td>\n",
       "      <td>0.731941</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc few_shot_type  \\\n",
       "24                       0.349471                 0.344371        prompt   \n",
       "33                       0.742779                 0.731941        prompt   \n",
       "\n",
       "   model_name_or_path  gradient_accumulation_steps  meta_train_batch_size  \\\n",
       "24      roberta-large                            1                      4   \n",
       "33      roberta-large                            1                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "24                    4   100             80                None   \n",
       "33                    4   100             80                 mlp   \n",
       "\n",
       "    learning_rate  \n",
       "24           0.01  \n",
       "33           0.01  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.01) & (result_frame['prompt_length']==80) \n",
    "                 &(result_frame['model_name_or_path']=='roberta-large')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d0497f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.40988608624898293, 'mnli_test_eval_mnli/acc': 0.40672440142638816, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5772986167615948, 'mnli_test_eval_mnli/acc': 0.5727967396841569, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.34997965825874694, 'mnli_test_eval_mnli/acc': 0.3543555781966378, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7953620829943043, 'mnli_test_eval_mnli/acc': 0.7860417727967397, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8129576891781937, 'mnli_test_eval_mnli/acc': 0.8042791645440652, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.858726606997559, 'mnli_test_eval_mnli/acc': 0.8553234844625573, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8628966639544345, 'mnli_test_eval_mnli/acc': 0.8552215995924605, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8596419853539463, 'mnli_test_eval_mnli/acc': 0.8542027508914927, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8454027664768105, 'mnli_test_eval_mnli/acc': 0.8381049414161997, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8435720097640358, 'mnli_test_eval_mnli/acc': 0.8395313295975547, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8550650935720098, 'mnli_test_eval_mnli/acc': 0.8479877738155884, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.1}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8489625711960944, 'mnli_test_eval_mnli/acc': 0.8461538461538461, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8457078925956062, 'mnli_test_eval_mnli/acc': 0.8415690269994905, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8541497152156224, 'mnli_test_eval_mnli/acc': 0.8503311258278146, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.01}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8574043938161107, 'mnli_test_eval_mnli/acc': 0.8492103922567499, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.8604556550040684, 'mnli_test_eval_mnli/acc': 0.8576668364747835, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 60, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.861879576891782, 'mnli_test_eval_mnli/acc': 0.8548140601120734, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "task = 'continuous_prompt_deberta'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a5bf07d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.409886</td>\n",
       "      <td>0.406724</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.577299</td>\n",
       "      <td>0.572797</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.349980</td>\n",
       "      <td>0.354356</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795362</td>\n",
       "      <td>0.786042</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.812958</td>\n",
       "      <td>0.804279</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.858727</td>\n",
       "      <td>0.855323</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.862897</td>\n",
       "      <td>0.855222</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.859642</td>\n",
       "      <td>0.854203</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.845403</td>\n",
       "      <td>0.838105</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.843572</td>\n",
       "      <td>0.839531</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.855065</td>\n",
       "      <td>0.847988</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.848963</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.845708</td>\n",
       "      <td>0.841569</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.854150</td>\n",
       "      <td>0.850331</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.857404</td>\n",
       "      <td>0.849210</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.860456</td>\n",
       "      <td>0.857667</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.861880</td>\n",
       "      <td>0.854814</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc few_shot_type  \\\n",
       "0                        0.409886                 0.406724        prompt   \n",
       "1                        0.577299                 0.572797        prompt   \n",
       "2                        0.349980                 0.354356        prompt   \n",
       "3                        0.795362                 0.786042        prompt   \n",
       "4                        0.812958                 0.804279        prompt   \n",
       "5                        0.858727                 0.855323        prompt   \n",
       "6                        0.862897                 0.855222        prompt   \n",
       "7                        0.859642                 0.854203        prompt   \n",
       "8                        0.845403                 0.838105        prompt   \n",
       "9                        0.843572                 0.839531        prompt   \n",
       "10                       0.855065                 0.847988        prompt   \n",
       "11                       0.848963                 0.846154        prompt   \n",
       "12                       0.845708                 0.841569        prompt   \n",
       "13                       0.854150                 0.850331        prompt   \n",
       "14                       0.857404                 0.849210        prompt   \n",
       "15                       0.860456                 0.857667        prompt   \n",
       "16                       0.861880                 0.854814        prompt   \n",
       "\n",
       "         model_name_or_path  gradient_accumulation_steps  \\\n",
       "0   microsoft/deberta-large                            1   \n",
       "1   microsoft/deberta-large                            1   \n",
       "2   microsoft/deberta-large                            1   \n",
       "3   microsoft/deberta-large                            1   \n",
       "4   microsoft/deberta-large                            1   \n",
       "5   microsoft/deberta-large                            1   \n",
       "6   microsoft/deberta-large                            1   \n",
       "7   microsoft/deberta-large                            1   \n",
       "8   microsoft/deberta-large                            1   \n",
       "9   microsoft/deberta-large                            1   \n",
       "10  microsoft/deberta-large                            1   \n",
       "11  microsoft/deberta-large                            1   \n",
       "12  microsoft/deberta-large                            1   \n",
       "13  microsoft/deberta-large                            1   \n",
       "14  microsoft/deberta-large                            1   \n",
       "15  microsoft/deberta-large                            1   \n",
       "16  microsoft/deberta-large                            1   \n",
       "\n",
       "    meta_train_batch_size  un_train_batch_size  seed  prompt_length  \\\n",
       "0                       4                    4   100             40   \n",
       "1                       4                    4   100             60   \n",
       "2                       4                    4   100             80   \n",
       "3                       4                    4   100             60   \n",
       "4                       4                    4   100             80   \n",
       "5                       4                    4   100             40   \n",
       "6                       4                    4   100             60   \n",
       "7                       4                    4   100             80   \n",
       "8                       4                    4   100             40   \n",
       "9                       4                    4   100             60   \n",
       "10                      4                    4   100             80   \n",
       "11                      4                    4   100             40   \n",
       "12                      4                    4   100             60   \n",
       "13                      4                    4   100             80   \n",
       "14                      4                    4   100             40   \n",
       "15                      4                    4   100             60   \n",
       "16                      4                    4   100             80   \n",
       "\n",
       "   prompt_encoder_type  learning_rate  \n",
       "0                 None          0.100  \n",
       "1                 None          0.100  \n",
       "2                 None          0.100  \n",
       "3                 None          0.010  \n",
       "4                 None          0.010  \n",
       "5                 None          0.001  \n",
       "6                 None          0.001  \n",
       "7                 None          0.001  \n",
       "8                  mlp          0.100  \n",
       "9                  mlp          0.100  \n",
       "10                 mlp          0.100  \n",
       "11                 mlp          0.010  \n",
       "12                 mlp          0.010  \n",
       "13                 mlp          0.010  \n",
       "14                 mlp          0.001  \n",
       "15                 mlp          0.001  \n",
       "16                 mlp          0.001  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "03090160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.01\n",
      "0.8256749872643911\n",
      "0.8314279902359643\n",
      "learning_rate 0.001\n",
      "0.8544065206316863\n",
      "0.8601674803363167\n",
      "prompt_encoder_type mlp\n",
      "0.849957547970793\n",
      "0.854759967453214\n",
      "prompt_encoder_type None\n",
      "0.831013754457463\n",
      "0.8379170056956877\n",
      "prompt_length 40\n",
      "0.8502292409577178\n",
      "0.8550311906699214\n",
      "prompt_length 60\n",
      "0.8351248089658685\n",
      "0.8411055736371034\n",
      "prompt_length 80\n",
      "0.8409067753438614\n",
      "0.847157241659886\n"
     ]
    }
   ],
   "source": [
    "att_dict = {'learning_rate':[0.01, 0.001], 'prompt_encoder_type':['mlp', 'None'], 'prompt_length' :[40, 60, 80]}\n",
    "for att in att_dict:\n",
    "    for val in att_dict[att]:\n",
    "        print(att, val)\n",
    "        print(result_frame.loc[(result_frame[att]==val) &  (result_frame['learning_rate'] !=0.1)\n",
    "                 &(result_frame['model_name_or_path']=='microsoft/deberta-large')]['mnli_test_eval_mnli/acc'].mean())\n",
    "        print(result_frame.loc[(result_frame[att]==val) &  (result_frame['learning_rate'] !=0.1)\n",
    "                 &(result_frame['model_name_or_path']=='microsoft/deberta-large')]['mnli-mm_test_eval_mnli-mm/acc'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d73acde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7608828315703824, 'mnli_test_eval_mnli/acc': 0.7395822720326032, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.0001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 42, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6745321399511798, 'mnli_test_eval_mnli/acc': 0.65206316861946, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 42, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7278275020341741, 'mnli_test_eval_mnli/acc': 0.7195109526235354, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.0001, 'soft_label': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 87, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7511187957689178, 'mnli_test_eval_mnli/acc': 0.7409067753438614, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 87, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6913140764849471, 'mnli_test_eval_mnli/acc': 0.6746816097809475, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 1e-05, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 87, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7552888527257934, 'mnli_test_eval_mnli/acc': 0.7316352521650535, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 42, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7487794955248169, 'mnli_test_eval_mnli/acc': 0.7365257259296994, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.0001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.735353946297803, 'mnli_test_eval_mnli/acc': 0.7233825776872135, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 1e-05, 'soft_label': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 87, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7487794955248169, 'mnli_test_eval_mnli/acc': 0.7365257259296994, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 1e-05, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7487794955248169, 'mnli_test_eval_mnli/acc': 0.7365257259296994, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.0001, 'soft_label': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 100, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6913140764849471, 'mnli_test_eval_mnli/acc': 0.6746816097809475, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.0001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 87, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7306753458096013, 'mnli_test_eval_mnli/acc': 0.7192052980132451, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.0001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 21, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7158258746948739, 'mnli_test_eval_mnli/acc': 0.6960774325012735, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 1e-05, 'soft_label': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 13, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6770748576078113, 'mnli_test_eval_mnli/acc': 0.6596026490066225, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.0001, 'soft_label': 1, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 13, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.7864117168429617, 'mnli_test_eval_mnli/acc': 0.7779928680590932, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 8, 'seed': 21, 'prompt_length': 40, 'prompt_encoder_type': 'mlp', 'learning_rate': 5e-06}\n"
     ]
    }
   ],
   "source": [
    "args_list = ['mnli-mm_test_eval_mnli-mm/acc', 'mnli_test_eval_mnli/acc', \n",
    "             'few_shot_type', 'model_name_or_path', 'gradient_accumulation_steps',  'prompt_learning_rate', 'soft_label',\n",
    "             'meta_train_batch_size', 'un_train_batch_size', 'seed', 'prompt_length', 'prompt_encoder_type', 'learning_rate']\n",
    "\n",
    "task = 'meta_st_continuous_large_model_deberta'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/phillytools/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8729a07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>prompt_learning_rate</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.760883</td>\n",
       "      <td>0.739582</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.674532</td>\n",
       "      <td>0.652063</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.727828</td>\n",
       "      <td>0.719511</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.740907</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691314</td>\n",
       "      <td>0.674682</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.755289</td>\n",
       "      <td>0.731635</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.748779</td>\n",
       "      <td>0.736526</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.735354</td>\n",
       "      <td>0.723383</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.748779</td>\n",
       "      <td>0.736526</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.748779</td>\n",
       "      <td>0.736526</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.691314</td>\n",
       "      <td>0.674682</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.730675</td>\n",
       "      <td>0.719205</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715826</td>\n",
       "      <td>0.696077</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.677075</td>\n",
       "      <td>0.659603</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.786412</td>\n",
       "      <td>0.777993</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc few_shot_type  \\\n",
       "0                        0.760883                 0.739582        prompt   \n",
       "1                        0.674532                 0.652063        prompt   \n",
       "2                        0.727828                 0.719511        prompt   \n",
       "3                        0.751119                 0.740907        prompt   \n",
       "4                        0.691314                 0.674682        prompt   \n",
       "5                        0.755289                 0.731635        prompt   \n",
       "6                        0.748779                 0.736526        prompt   \n",
       "7                        0.735354                 0.723383        prompt   \n",
       "8                        0.748779                 0.736526        prompt   \n",
       "9                        0.748779                 0.736526        prompt   \n",
       "10                       0.691314                 0.674682        prompt   \n",
       "11                       0.730675                 0.719205        prompt   \n",
       "12                       0.715826                 0.696077        prompt   \n",
       "13                       0.677075                 0.659603        prompt   \n",
       "14                       0.786412                 0.777993        prompt   \n",
       "\n",
       "         model_name_or_path  gradient_accumulation_steps  \\\n",
       "0   microsoft/deberta-large                            1   \n",
       "1   microsoft/deberta-large                            1   \n",
       "2   microsoft/deberta-large                            1   \n",
       "3   microsoft/deberta-large                            1   \n",
       "4   microsoft/deberta-large                            1   \n",
       "5   microsoft/deberta-large                            1   \n",
       "6   microsoft/deberta-large                            1   \n",
       "7   microsoft/deberta-large                            1   \n",
       "8   microsoft/deberta-large                            1   \n",
       "9   microsoft/deberta-large                            1   \n",
       "10  microsoft/deberta-large                            1   \n",
       "11  microsoft/deberta-large                            1   \n",
       "12  microsoft/deberta-large                            1   \n",
       "13  microsoft/deberta-large                            1   \n",
       "14  microsoft/deberta-large                            1   \n",
       "\n",
       "    prompt_learning_rate  soft_label  meta_train_batch_size  \\\n",
       "0                0.00010           0                      4   \n",
       "1                0.00100           0                      4   \n",
       "2                0.00010           1                      4   \n",
       "3                0.00100           1                      4   \n",
       "4                0.00001           0                      4   \n",
       "5                0.00100           1                      4   \n",
       "6                0.00010           0                      4   \n",
       "7                0.00001           1                      4   \n",
       "8                0.00001           0                      4   \n",
       "9                0.00010           1                      4   \n",
       "10               0.00010           0                      4   \n",
       "11               0.00010           0                      4   \n",
       "12               0.00001           1                      4   \n",
       "13               0.00010           1                      4   \n",
       "14               0.00100           0                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "0                     8    42             40                 mlp   \n",
       "1                     8    42             40                 mlp   \n",
       "2                     8    87             40                 mlp   \n",
       "3                     8    87             40                 mlp   \n",
       "4                     8    87             40                 mlp   \n",
       "5                     8    42             40                 mlp   \n",
       "6                     8   100             40                 mlp   \n",
       "7                     8    87             40                 mlp   \n",
       "8                     8   100             40                 mlp   \n",
       "9                     8   100             40                 mlp   \n",
       "10                    8    87             40                 mlp   \n",
       "11                    8    21             40                 mlp   \n",
       "12                    8    13             40                 mlp   \n",
       "13                    8    13             40                 mlp   \n",
       "14                    8    21             40                 mlp   \n",
       "\n",
       "    learning_rate  \n",
       "0        0.000005  \n",
       "1        0.000005  \n",
       "2        0.000005  \n",
       "3        0.000005  \n",
       "4        0.000005  \n",
       "5        0.000005  \n",
       "6        0.000005  \n",
       "7        0.000005  \n",
       "8        0.000005  \n",
       "9        0.000005  \n",
       "10       0.000005  \n",
       "11       0.000005  \n",
       "12       0.000005  \n",
       "13       0.000005  \n",
       "14       0.000005  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5093af49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6338486574450773, 'mnli_test_eval_mnli/acc': 0.6147733061640347, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5617371847030106, 'mnli_test_eval_mnli/acc': 0.547427407030056, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5627542717656632, 'mnli_test_eval_mnli/acc': 0.5439633214467652, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.567432872253865, 'mnli_test_eval_mnli/acc': 0.5499745287824758, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4401952807160293, 'mnli_test_eval_mnli/acc': 0.4425878757004585, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.48942229454841335, 'mnli_test_eval_mnli/acc': 0.46541008660213956, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5844182262001627, 'mnli_test_eval_mnli/acc': 0.5517065715741213, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5333604556550041, 'mnli_test_eval_mnli/acc': 0.49821701477330615, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5274613506916193, 'mnli_test_eval_mnli/acc': 0.5212429954151808, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.3695077298616762, 'mnli_test_eval_mnli/acc': 0.3628120224146714, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4934906427990236, 'mnli_test_eval_mnli/acc': 0.4600101884870097, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5104759967453214, 'mnli_test_eval_mnli/acc': 0.5022924095771778, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4608421480878763, 'mnli_test_eval_mnli/acc': 0.4618441161487519, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5569568755085436, 'mnli_test_eval_mnli/acc': 0.5261334691798268, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6136086248982913, 'mnli_test_eval_mnli/acc': 0.6046867040244523, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5141375101708706, 'mnli_test_eval_mnli/acc': 0.5122771268466633, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5268510984540277, 'mnli_test_eval_mnli/acc': 0.5140091696383087, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.45941822620016276, 'mnli_test_eval_mnli/acc': 0.46245542536933265, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4808787632221318, 'mnli_test_eval_mnli/acc': 0.4696892511462048, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.557160292921074, 'mnli_test_eval_mnli/acc': 0.5412124299541519, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4631814483319772, 'mnli_test_eval_mnli/acc': 0.45369332654100863, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5101708706265257, 'mnli_test_eval_mnli/acc': 0.5071828833418237, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.524613506916192, 'mnli_test_eval_mnli/acc': 0.5094243504839532, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5658055329536208, 'mnli_test_eval_mnli/acc': 0.5562913907284768, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5327502034174125, 'mnli_test_eval_mnli/acc': 0.49882832399388694, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4895240032546786, 'mnli_test_eval_mnli/acc': 0.4882322975038207, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.45880797396257117, 'mnli_test_eval_mnli/acc': 0.46367804381049416, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5175956061838893, 'mnli_test_eval_mnli/acc': 0.5159449821701477, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5606183889340928, 'mnli_test_eval_mnli/acc': 0.5282730514518594, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5577705451586655, 'mnli_test_eval_mnli/acc': 0.5387671930718289, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5526851098454028, 'mnli_test_eval_mnli/acc': 0.5410086602139582, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.568653376729048, 'mnli_test_eval_mnli/acc': 0.5403973509933775, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.415480065093572, 'mnli_test_eval_mnli/acc': 0.4163015792154865, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5341741253051261, 'mnli_test_eval_mnli/acc': 0.5215486500254712, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5618388934092758, 'mnli_test_eval_mnli/acc': 0.5427407030056036, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5656021155410903, 'mnli_test_eval_mnli/acc': 0.5521141110545084, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6471724979658259, 'mnli_test_eval_mnli/acc': 0.6334182373917473, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6675142392188771, 'mnli_test_eval_mnli/acc': 0.6536933265410086, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4692839707078926, 'mnli_test_eval_mnli/acc': 0.4674477840040754, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.39208706265256305, 'mnli_test_eval_mnli/acc': 0.38848700967906263, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5634662327095199, 'mnli_test_eval_mnli/acc': 0.5499745287824758, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6510374288039056, 'mnli_test_eval_mnli/acc': 0.6370860927152318, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.47620016273393, 'mnli_test_eval_mnli/acc': 0.45084055017829855, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5350895036615134, 'mnli_test_eval_mnli/acc': 0.5340804890473765, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5652969894222946, 'mnli_test_eval_mnli/acc': 0.5598573611818645, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5797396257119609, 'mnli_test_eval_mnli/acc': 0.5727967396841569, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.572213181448332, 'mnli_test_eval_mnli/acc': 0.5415180845644422, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6023189585028479, 'mnli_test_eval_mnli/acc': 0.577585328578706, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5180024410089503, 'mnli_test_eval_mnli/acc': 0.5089149261334692, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.53966639544345, 'mnli_test_eval_mnli/acc': 0.5370351502801833, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4457892595606184, 'mnli_test_eval_mnli/acc': 0.43005603667855324, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5276647681041498, 'mnli_test_eval_mnli/acc': 0.5195109526235354, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.629780309194467, 'mnli_test_eval_mnli/acc': 0.6080489047376465, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.47426769731489016, 'mnli_test_eval_mnli/acc': 0.46388181355068775, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6693449959316518, 'mnli_test_eval_mnli/acc': 0.6565461029037188, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6308991049633849, 'mnli_test_eval_mnli/acc': 0.614569536423841, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6568348250610252, 'mnli_test_eval_mnli/acc': 0.6431991849210392, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6529698942229455, 'mnli_test_eval_mnli/acc': 0.6152827305145185, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4707078925956062, 'mnli_test_eval_mnli/acc': 0.46459500764136524, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.6402563059397884, 'mnli_test_eval_mnli/acc': 0.5937850229240957, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5749593165174939, 'mnli_test_eval_mnli/acc': 0.5446765155374427, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.40866558177379986, 'mnli_test_eval_mnli/acc': 0.4085583290881304, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.47030105777054515, 'mnli_test_eval_mnli/acc': 0.4489047376464595, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5843165174938975, 'mnli_test_eval_mnli/acc': 0.5515028018339276, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.49989829129373475, 'mnli_test_eval_mnli/acc': 0.48965868568517573, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.549633848657445, 'mnli_test_eval_mnli/acc': 0.5413143148242486, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5393612693246542, 'mnli_test_eval_mnli/acc': 0.5168619460010189, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4205655004068348, 'mnli_test_eval_mnli/acc': 0.41793173713703513, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.483726606997559, 'mnli_test_eval_mnli/acc': 0.46673458991339783, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5689585028478438, 'mnli_test_eval_mnli/acc': 0.5590422822210902, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 80, 'prompt_encoder_type': 'None', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4544344995931652, 'mnli_test_eval_mnli/acc': 0.445746306673459, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4948128559804719, 'mnli_test_eval_mnli/acc': 0.487111563932756, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5247152156224573, 'mnli_test_eval_mnli/acc': 0.5018848700967906, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.0001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4497558991049634, 'mnli_test_eval_mnli/acc': 0.435048395313296, 'demo_condon_steps': 1000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 42, 'prompt_length': 80, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "args_list = ['mnli-mm_test_eval_mnli-mm/acc', 'mnli_test_eval_mnli/acc',  'demo_condon_steps',\n",
    "             'few_shot_type', 'model_name_or_path', 'gradient_accumulation_steps',  'prompt_learning_rate', 'soft_label',\n",
    "             'meta_train_batch_size', 'un_train_batch_size', 'seed', 'prompt_length', 'prompt_encoder_type', 'learning_rate']\n",
    "\n",
    "task = 'con_prompt_condensen'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b87544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>demo_condon_steps</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>prompt_learning_rate</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633849</td>\n",
       "      <td>0.614773</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561737</td>\n",
       "      <td>0.547427</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562754</td>\n",
       "      <td>0.543963</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567433</td>\n",
       "      <td>0.549975</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.440195</td>\n",
       "      <td>0.442588</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.489422</td>\n",
       "      <td>0.465410</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.584418</td>\n",
       "      <td>0.551707</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.533360</td>\n",
       "      <td>0.498217</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.527461</td>\n",
       "      <td>0.521243</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.369508</td>\n",
       "      <td>0.362812</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.493491</td>\n",
       "      <td>0.460010</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.510476</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.460842</td>\n",
       "      <td>0.461844</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.556957</td>\n",
       "      <td>0.526133</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.613609</td>\n",
       "      <td>0.604687</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.514138</td>\n",
       "      <td>0.512277</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.526851</td>\n",
       "      <td>0.514009</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.459418</td>\n",
       "      <td>0.462455</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.480879</td>\n",
       "      <td>0.469689</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.557160</td>\n",
       "      <td>0.541212</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.463181</td>\n",
       "      <td>0.453693</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.510171</td>\n",
       "      <td>0.507183</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.524614</td>\n",
       "      <td>0.509424</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.565806</td>\n",
       "      <td>0.556291</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.532750</td>\n",
       "      <td>0.498828</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.489524</td>\n",
       "      <td>0.488232</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.458808</td>\n",
       "      <td>0.463678</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.517596</td>\n",
       "      <td>0.515945</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.560618</td>\n",
       "      <td>0.528273</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.557771</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.552685</td>\n",
       "      <td>0.541009</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.568653</td>\n",
       "      <td>0.540397</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.415480</td>\n",
       "      <td>0.416302</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.534174</td>\n",
       "      <td>0.521549</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.561839</td>\n",
       "      <td>0.542741</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.565602</td>\n",
       "      <td>0.552114</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.647172</td>\n",
       "      <td>0.633418</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.667514</td>\n",
       "      <td>0.653693</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.469284</td>\n",
       "      <td>0.467448</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.392087</td>\n",
       "      <td>0.388487</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.563466</td>\n",
       "      <td>0.549975</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.651037</td>\n",
       "      <td>0.637086</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.476200</td>\n",
       "      <td>0.450841</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.535090</td>\n",
       "      <td>0.534080</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.565297</td>\n",
       "      <td>0.559857</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.579740</td>\n",
       "      <td>0.572797</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.602319</td>\n",
       "      <td>0.577585</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.518002</td>\n",
       "      <td>0.508915</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.539666</td>\n",
       "      <td>0.537035</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.445789</td>\n",
       "      <td>0.430056</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.527665</td>\n",
       "      <td>0.519511</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.572213</td>\n",
       "      <td>0.541518</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc  demo_condon_steps  \\\n",
       "0                        0.633849                 0.614773               3000   \n",
       "1                        0.561737                 0.547427               1000   \n",
       "2                        0.562754                 0.543963               1000   \n",
       "3                        0.567433                 0.549975               3000   \n",
       "4                        0.440195                 0.442588               3000   \n",
       "5                        0.489422                 0.465410               1000   \n",
       "6                        0.584418                 0.551707               1000   \n",
       "7                        0.533360                 0.498217               3000   \n",
       "8                        0.527461                 0.521243               1000   \n",
       "9                        0.369508                 0.362812               3000   \n",
       "10                       0.493491                 0.460010               1000   \n",
       "11                       0.510476                 0.502292               3000   \n",
       "12                       0.460842                 0.461844               3000   \n",
       "13                       0.556957                 0.526133               1000   \n",
       "14                       0.613609                 0.604687               3000   \n",
       "15                       0.514138                 0.512277               3000   \n",
       "16                       0.526851                 0.514009               1000   \n",
       "17                       0.459418                 0.462455               3000   \n",
       "18                       0.480879                 0.469689               3000   \n",
       "19                       0.557160                 0.541212               3000   \n",
       "20                       0.463181                 0.453693               1000   \n",
       "21                       0.510171                 0.507183               1000   \n",
       "22                       0.524614                 0.509424               1000   \n",
       "23                       0.565806                 0.556291               1000   \n",
       "24                       0.532750                 0.498828               1000   \n",
       "25                       0.489524                 0.488232               1000   \n",
       "26                       0.458808                 0.463678               1000   \n",
       "27                       0.517596                 0.515945               3000   \n",
       "28                       0.560618                 0.528273               1000   \n",
       "29                       0.557771                 0.538767               3000   \n",
       "30                       0.552685                 0.541009               3000   \n",
       "31                       0.568653                 0.540397               1000   \n",
       "32                       0.415480                 0.416302               3000   \n",
       "33                       0.534174                 0.521549               3000   \n",
       "34                       0.561839                 0.542741               1000   \n",
       "35                       0.565602                 0.552114               3000   \n",
       "36                       0.647172                 0.633418               1000   \n",
       "37                       0.667514                 0.653693               1000   \n",
       "38                       0.469284                 0.467448               3000   \n",
       "39                       0.392087                 0.388487               1000   \n",
       "40                       0.563466                 0.549975               1000   \n",
       "41                       0.651037                 0.637086               3000   \n",
       "42                       0.476200                 0.450841               1000   \n",
       "43                       0.535090                 0.534080               1000   \n",
       "44                       0.565297                 0.559857               3000   \n",
       "45                       0.579740                 0.572797               1000   \n",
       "46                       0.602319                 0.577585               1000   \n",
       "47                       0.518002                 0.508915               1000   \n",
       "48                       0.539666                 0.537035               3000   \n",
       "49                       0.445789                 0.430056               3000   \n",
       "50                       0.527665                 0.519511               1000   \n",
       "51                       0.572213                 0.541518               3000   \n",
       "\n",
       "   few_shot_type       model_name_or_path  gradient_accumulation_steps  \\\n",
       "0         prompt  microsoft/deberta-large                            1   \n",
       "1         prompt            roberta-large                            1   \n",
       "2         prompt  microsoft/deberta-large                            1   \n",
       "3         prompt            roberta-large                            1   \n",
       "4         prompt  microsoft/deberta-large                            1   \n",
       "5         prompt            roberta-large                            1   \n",
       "6         prompt  microsoft/deberta-large                            1   \n",
       "7         prompt  microsoft/deberta-large                            1   \n",
       "8         prompt  microsoft/deberta-large                            1   \n",
       "9         prompt  microsoft/deberta-large                            1   \n",
       "10        prompt            roberta-large                            1   \n",
       "11        prompt            roberta-large                            1   \n",
       "12        prompt            roberta-large                            1   \n",
       "13        prompt  microsoft/deberta-large                            1   \n",
       "14        prompt  microsoft/deberta-large                            1   \n",
       "15        prompt            roberta-large                            1   \n",
       "16        prompt            roberta-large                            1   \n",
       "17        prompt            roberta-large                            1   \n",
       "18        prompt  microsoft/deberta-large                            1   \n",
       "19        prompt            roberta-large                            1   \n",
       "20        prompt  microsoft/deberta-large                            1   \n",
       "21        prompt            roberta-large                            1   \n",
       "22        prompt  microsoft/deberta-large                            1   \n",
       "23        prompt            roberta-large                            1   \n",
       "24        prompt  microsoft/deberta-large                            1   \n",
       "25        prompt            roberta-large                            1   \n",
       "26        prompt  microsoft/deberta-large                            1   \n",
       "27        prompt            roberta-large                            1   \n",
       "28        prompt  microsoft/deberta-large                            1   \n",
       "29        prompt  microsoft/deberta-large                            1   \n",
       "30        prompt            roberta-large                            1   \n",
       "31        prompt  microsoft/deberta-large                            1   \n",
       "32        prompt            roberta-large                            1   \n",
       "33        prompt            roberta-large                            1   \n",
       "34        prompt            roberta-large                            1   \n",
       "35        prompt  microsoft/deberta-large                            1   \n",
       "36        prompt  microsoft/deberta-large                            1   \n",
       "37        prompt  microsoft/deberta-large                            1   \n",
       "38        prompt            roberta-large                            1   \n",
       "39        prompt  microsoft/deberta-large                            1   \n",
       "40        prompt            roberta-large                            1   \n",
       "41        prompt  microsoft/deberta-large                            1   \n",
       "42        prompt            roberta-large                            1   \n",
       "43        prompt            roberta-large                            1   \n",
       "44        prompt            roberta-large                            1   \n",
       "45        prompt  microsoft/deberta-large                            1   \n",
       "46        prompt  microsoft/deberta-large                            1   \n",
       "47        prompt            roberta-large                            1   \n",
       "48        prompt            roberta-large                            1   \n",
       "49        prompt  microsoft/deberta-large                            1   \n",
       "50        prompt            roberta-large                            1   \n",
       "51        prompt  microsoft/deberta-large                            1   \n",
       "\n",
       "    prompt_learning_rate  soft_label  meta_train_batch_size  \\\n",
       "0                  0.001           0                      4   \n",
       "1                  0.001           0                      4   \n",
       "2                  0.001           0                      4   \n",
       "3                  0.001           0                      4   \n",
       "4                  0.001           0                      4   \n",
       "5                  0.001           0                      4   \n",
       "6                  0.001           0                      4   \n",
       "7                  0.001           0                      4   \n",
       "8                  0.001           0                      4   \n",
       "9                  0.001           0                      4   \n",
       "10                 0.001           0                      4   \n",
       "11                 0.001           0                      4   \n",
       "12                 0.001           0                      4   \n",
       "13                 0.001           0                      4   \n",
       "14                 0.001           0                      4   \n",
       "15                 0.001           0                      4   \n",
       "16                 0.001           0                      4   \n",
       "17                 0.001           0                      4   \n",
       "18                 0.001           0                      4   \n",
       "19                 0.001           0                      4   \n",
       "20                 0.001           0                      4   \n",
       "21                 0.001           0                      4   \n",
       "22                 0.001           0                      4   \n",
       "23                 0.001           0                      4   \n",
       "24                 0.001           0                      4   \n",
       "25                 0.001           0                      4   \n",
       "26                 0.001           0                      4   \n",
       "27                 0.001           0                      4   \n",
       "28                 0.001           0                      4   \n",
       "29                 0.001           0                      4   \n",
       "30                 0.001           0                      4   \n",
       "31                 0.001           0                      4   \n",
       "32                 0.001           0                      4   \n",
       "33                 0.001           0                      4   \n",
       "34                 0.001           0                      4   \n",
       "35                 0.001           0                      4   \n",
       "36                 0.001           0                      4   \n",
       "37                 0.001           0                      4   \n",
       "38                 0.001           0                      4   \n",
       "39                 0.001           0                      4   \n",
       "40                 0.001           0                      4   \n",
       "41                 0.001           0                      4   \n",
       "42                 0.001           0                      4   \n",
       "43                 0.001           0                      4   \n",
       "44                 0.001           0                      4   \n",
       "45                 0.001           0                      4   \n",
       "46                 0.001           0                      4   \n",
       "47                 0.001           0                      4   \n",
       "48                 0.001           0                      4   \n",
       "49                 0.001           0                      4   \n",
       "50                 0.001           0                      4   \n",
       "51                 0.001           0                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "0                     4   100             80                 mlp   \n",
       "1                     4    13             80                 mlp   \n",
       "2                     4   100             80                 mlp   \n",
       "3                     4    87             80                None   \n",
       "4                     4    42             80                 mlp   \n",
       "5                     4    42             80                None   \n",
       "6                     4   100             80                None   \n",
       "7                     4    42             80                None   \n",
       "8                     4    21             80                None   \n",
       "9                     4   100             80                 mlp   \n",
       "10                    4    87             80                 mlp   \n",
       "11                    4    42             80                 mlp   \n",
       "12                    4   100             80                 mlp   \n",
       "13                    4    42             80                 mlp   \n",
       "14                    4    87             80                 mlp   \n",
       "15                    4    87             80                 mlp   \n",
       "16                    4    21             80                None   \n",
       "17                    4    21             80                 mlp   \n",
       "18                    4    87             80                None   \n",
       "19                    4    87             80                None   \n",
       "20                    4    13             80                 mlp   \n",
       "21                    4   100             80                None   \n",
       "22                    4    87             80                None   \n",
       "23                    4    87             80                None   \n",
       "24                    4    42             80                None   \n",
       "25                    4    21             80                 mlp   \n",
       "26                    4    87             80                 mlp   \n",
       "27                    4    13             80                 mlp   \n",
       "28                    4    87             80                None   \n",
       "29                    4    21             80                 mlp   \n",
       "30                    4    21             80                 mlp   \n",
       "31                    4    13             80                None   \n",
       "32                    4   100             80                 mlp   \n",
       "33                    4    21             80                None   \n",
       "34                    4    13             80                None   \n",
       "35                    4    21             80                None   \n",
       "36                    4   100             80                None   \n",
       "37                    4    21             80                 mlp   \n",
       "38                    4    42             80                 mlp   \n",
       "39                    4    87             80                 mlp   \n",
       "40                    4    42             80                None   \n",
       "41                    4    21             80                None   \n",
       "42                    4    42             80                 mlp   \n",
       "43                    4   100             80                None   \n",
       "44                    4    13             80                None   \n",
       "45                    4   100             80                 mlp   \n",
       "46                    4    42             80                 mlp   \n",
       "47                    4    87             80                 mlp   \n",
       "48                    4    87             80                 mlp   \n",
       "49                    4    87             80                 mlp   \n",
       "50                    4    21             80                 mlp   \n",
       "51                    4    42             80                None   \n",
       "\n",
       "    learning_rate  \n",
       "0          0.0010  \n",
       "1          0.0001  \n",
       "2          0.0010  \n",
       "3          0.0001  \n",
       "4          0.0001  \n",
       "5          0.0010  \n",
       "6          0.0001  \n",
       "7          0.0001  \n",
       "8          0.0001  \n",
       "9          0.0001  \n",
       "10         0.0001  \n",
       "11         0.0010  \n",
       "12         0.0001  \n",
       "13         0.0010  \n",
       "14         0.0010  \n",
       "15         0.0001  \n",
       "16         0.0010  \n",
       "17         0.0010  \n",
       "18         0.0010  \n",
       "19         0.0010  \n",
       "20         0.0001  \n",
       "21         0.0010  \n",
       "22         0.0001  \n",
       "23         0.0010  \n",
       "24         0.0001  \n",
       "25         0.0010  \n",
       "26         0.0010  \n",
       "27         0.0010  \n",
       "28         0.0010  \n",
       "29         0.0010  \n",
       "30         0.0001  \n",
       "31         0.0001  \n",
       "32         0.0010  \n",
       "33         0.0010  \n",
       "34         0.0010  \n",
       "35         0.0001  \n",
       "36         0.0010  \n",
       "37         0.0010  \n",
       "38         0.0001  \n",
       "39         0.0001  \n",
       "40         0.0001  \n",
       "41         0.0010  \n",
       "42         0.0001  \n",
       "43         0.0001  \n",
       "44         0.0001  \n",
       "45         0.0001  \n",
       "46         0.0001  \n",
       "47         0.0010  \n",
       "48         0.0010  \n",
       "49         0.0001  \n",
       "50         0.0001  \n",
       "51         0.0010  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b0ffd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>demo_condon_steps</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>prompt_learning_rate</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633849</td>\n",
       "      <td>0.614773</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.613609</td>\n",
       "      <td>0.604687</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.480879</td>\n",
       "      <td>0.469689</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.557771</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.651037</td>\n",
       "      <td>0.637086</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.572213</td>\n",
       "      <td>0.541518</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.629780</td>\n",
       "      <td>0.608049</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.669345</td>\n",
       "      <td>0.656546</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.640256</td>\n",
       "      <td>0.593785</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.584317</td>\n",
       "      <td>0.551503</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc  demo_condon_steps  \\\n",
       "0                        0.633849                 0.614773               3000   \n",
       "14                       0.613609                 0.604687               3000   \n",
       "18                       0.480879                 0.469689               3000   \n",
       "29                       0.557771                 0.538767               3000   \n",
       "41                       0.651037                 0.637086               3000   \n",
       "46                       0.572213                 0.541518               3000   \n",
       "52                       0.629780                 0.608049               3000   \n",
       "54                       0.669345                 0.656546               3000   \n",
       "59                       0.640256                 0.593785               3000   \n",
       "63                       0.584317                 0.551503               3000   \n",
       "\n",
       "   few_shot_type       model_name_or_path  gradient_accumulation_steps  \\\n",
       "0         prompt  microsoft/deberta-large                            1   \n",
       "14        prompt  microsoft/deberta-large                            1   \n",
       "18        prompt  microsoft/deberta-large                            1   \n",
       "29        prompt  microsoft/deberta-large                            1   \n",
       "41        prompt  microsoft/deberta-large                            1   \n",
       "46        prompt  microsoft/deberta-large                            1   \n",
       "52        prompt  microsoft/deberta-large                            1   \n",
       "54        prompt  microsoft/deberta-large                            1   \n",
       "59        prompt  microsoft/deberta-large                            1   \n",
       "63        prompt  microsoft/deberta-large                            1   \n",
       "\n",
       "    prompt_learning_rate  soft_label  meta_train_batch_size  \\\n",
       "0                  0.001           0                      4   \n",
       "14                 0.001           0                      4   \n",
       "18                 0.001           0                      4   \n",
       "29                 0.001           0                      4   \n",
       "41                 0.001           0                      4   \n",
       "46                 0.001           0                      4   \n",
       "52                 0.001           0                      4   \n",
       "54                 0.001           0                      4   \n",
       "59                 0.001           0                      4   \n",
       "63                 0.001           0                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "0                     4   100             80                 mlp   \n",
       "14                    4    87             80                 mlp   \n",
       "18                    4    87             80                None   \n",
       "29                    4    21             80                 mlp   \n",
       "41                    4    21             80                None   \n",
       "46                    4    42             80                None   \n",
       "52                    4   100             80                None   \n",
       "54                    4    13             80                None   \n",
       "59                    4    13             80                 mlp   \n",
       "63                    4    42             80                 mlp   \n",
       "\n",
       "    learning_rate  \n",
       "0           0.001  \n",
       "14          0.001  \n",
       "18          0.001  \n",
       "29          0.001  \n",
       "41          0.001  \n",
       "46          0.001  \n",
       "52          0.001  \n",
       "54          0.001  \n",
       "59          0.001  \n",
       "63          0.001  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.001) & (result_frame['demo_condon_steps']== 3000)&(result_frame['model_name_or_path']== 'microsoft/deberta-large')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "520b55ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>demo_condon_steps</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>prompt_learning_rate</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.510476</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.459418</td>\n",
       "      <td>0.462455</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.557160</td>\n",
       "      <td>0.541212</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.517596</td>\n",
       "      <td>0.515945</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.415480</td>\n",
       "      <td>0.416302</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.534174</td>\n",
       "      <td>0.521549</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.539666</td>\n",
       "      <td>0.537035</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.499898</td>\n",
       "      <td>0.489659</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.539361</td>\n",
       "      <td>0.516862</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.420566</td>\n",
       "      <td>0.417932</td>\n",
       "      <td>3000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc  demo_condon_steps  \\\n",
       "11                       0.510476                 0.502292               3000   \n",
       "17                       0.459418                 0.462455               3000   \n",
       "19                       0.557160                 0.541212               3000   \n",
       "27                       0.517596                 0.515945               3000   \n",
       "32                       0.415480                 0.416302               3000   \n",
       "33                       0.534174                 0.521549               3000   \n",
       "49                       0.539666                 0.537035               3000   \n",
       "64                       0.499898                 0.489659               3000   \n",
       "66                       0.539361                 0.516862               3000   \n",
       "67                       0.420566                 0.417932               3000   \n",
       "\n",
       "   few_shot_type model_name_or_path  gradient_accumulation_steps  \\\n",
       "11        prompt      roberta-large                            1   \n",
       "17        prompt      roberta-large                            1   \n",
       "19        prompt      roberta-large                            1   \n",
       "27        prompt      roberta-large                            1   \n",
       "32        prompt      roberta-large                            1   \n",
       "33        prompt      roberta-large                            1   \n",
       "49        prompt      roberta-large                            1   \n",
       "64        prompt      roberta-large                            1   \n",
       "66        prompt      roberta-large                            1   \n",
       "67        prompt      roberta-large                            1   \n",
       "\n",
       "    prompt_learning_rate  soft_label  meta_train_batch_size  \\\n",
       "11                 0.001           0                      4   \n",
       "17                 0.001           0                      4   \n",
       "19                 0.001           0                      4   \n",
       "27                 0.001           0                      4   \n",
       "32                 0.001           0                      4   \n",
       "33                 0.001           0                      4   \n",
       "49                 0.001           0                      4   \n",
       "64                 0.001           0                      4   \n",
       "66                 0.001           0                      4   \n",
       "67                 0.001           0                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "11                    4    42             80                 mlp   \n",
       "17                    4    21             80                 mlp   \n",
       "19                    4    87             80                None   \n",
       "27                    4    13             80                 mlp   \n",
       "32                    4   100             80                 mlp   \n",
       "33                    4    21             80                None   \n",
       "49                    4    87             80                 mlp   \n",
       "64                    4   100             80                None   \n",
       "66                    4    13             80                None   \n",
       "67                    4    42             80                None   \n",
       "\n",
       "    learning_rate  \n",
       "11          0.001  \n",
       "17          0.001  \n",
       "19          0.001  \n",
       "27          0.001  \n",
       "32          0.001  \n",
       "33          0.001  \n",
       "49          0.001  \n",
       "64          0.001  \n",
       "66          0.001  \n",
       "67          0.001  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.001) & (result_frame['demo_condon_steps']== 3000)&(result_frame['model_name_or_path']== 'roberta-large')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cf60607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnli-mm_test_eval_mnli-mm/acc</th>\n",
       "      <th>mnli_test_eval_mnli/acc</th>\n",
       "      <th>demo_condon_steps</th>\n",
       "      <th>few_shot_type</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>prompt_learning_rate</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>meta_train_batch_size</th>\n",
       "      <th>un_train_batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>prompt_encoder_type</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562754</td>\n",
       "      <td>0.543963</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.556957</td>\n",
       "      <td>0.526133</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.458808</td>\n",
       "      <td>0.463678</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.560618</td>\n",
       "      <td>0.528273</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.647172</td>\n",
       "      <td>0.633418</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.667514</td>\n",
       "      <td>0.653693</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.656835</td>\n",
       "      <td>0.643199</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.652970</td>\n",
       "      <td>0.615283</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.574959</td>\n",
       "      <td>0.544677</td>\n",
       "      <td>1000</td>\n",
       "      <td>prompt</td>\n",
       "      <td>microsoft/deberta-large</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mnli-mm_test_eval_mnli-mm/acc  mnli_test_eval_mnli/acc  demo_condon_steps  \\\n",
       "2                        0.562754                 0.543963               1000   \n",
       "13                       0.556957                 0.526133               1000   \n",
       "26                       0.458808                 0.463678               1000   \n",
       "28                       0.560618                 0.528273               1000   \n",
       "36                       0.647172                 0.633418               1000   \n",
       "37                       0.667514                 0.653693               1000   \n",
       "56                       0.656835                 0.643199               1000   \n",
       "57                       0.652970                 0.615283               1000   \n",
       "60                       0.574959                 0.544677               1000   \n",
       "\n",
       "   few_shot_type       model_name_or_path  gradient_accumulation_steps  \\\n",
       "2         prompt  microsoft/deberta-large                            1   \n",
       "13        prompt  microsoft/deberta-large                            1   \n",
       "26        prompt  microsoft/deberta-large                            1   \n",
       "28        prompt  microsoft/deberta-large                            1   \n",
       "36        prompt  microsoft/deberta-large                            1   \n",
       "37        prompt  microsoft/deberta-large                            1   \n",
       "56        prompt  microsoft/deberta-large                            1   \n",
       "57        prompt  microsoft/deberta-large                            1   \n",
       "60        prompt  microsoft/deberta-large                            1   \n",
       "\n",
       "    prompt_learning_rate  soft_label  meta_train_batch_size  \\\n",
       "2                  0.001           0                      4   \n",
       "13                 0.001           0                      4   \n",
       "26                 0.001           0                      4   \n",
       "28                 0.001           0                      4   \n",
       "36                 0.001           0                      4   \n",
       "37                 0.001           0                      4   \n",
       "56                 0.001           0                      4   \n",
       "57                 0.001           0                      4   \n",
       "60                 0.001           0                      4   \n",
       "\n",
       "    un_train_batch_size  seed  prompt_length prompt_encoder_type  \\\n",
       "2                     4   100             80                 mlp   \n",
       "13                    4    42             80                 mlp   \n",
       "26                    4    87             80                 mlp   \n",
       "28                    4    87             80                None   \n",
       "36                    4   100             80                None   \n",
       "37                    4    21             80                 mlp   \n",
       "56                    4    21             80                None   \n",
       "57                    4    42             80                None   \n",
       "60                    4    13             80                 mlp   \n",
       "\n",
       "    learning_rate  \n",
       "2           0.001  \n",
       "13          0.001  \n",
       "26          0.001  \n",
       "28          0.001  \n",
       "36          0.001  \n",
       "37          0.001  \n",
       "56          0.001  \n",
       "57          0.001  \n",
       "60          0.001  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame.loc[(result_frame['learning_rate']==0.0010) & (result_frame['demo_condon_steps']== 1000)&(result_frame['model_name_or_path']== 'microsoft/deberta-large')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5852850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.495626525630594, 'mnli_test_eval_mnli/acc': 0.497809475292919, 'demo_condon_steps': 0, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 100, 'prompt_length': 20, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.49755899104963386, 'mnli_test_eval_mnli/acc': 0.490983188996434, 'demo_condon_steps': 0, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 20, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5106794141578519, 'mnli_test_eval_mnli/acc': 0.5024961793173713, 'demo_condon_steps': 0, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 21, 'prompt_length': 40, 'prompt_encoder_type': 'None', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.46430024410089504, 'mnli_test_eval_mnli/acc': 0.4526744778400408, 'demo_condon_steps': 0, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 20, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.5243083807973963, 'mnli_test_eval_mnli/acc': 0.5196128374936322, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'microsoft/deberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 13, 'prompt_length': 20, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n",
      "{'mnli-mm_test_eval_mnli-mm/acc': 0.4923718470301058, 'mnli_test_eval_mnli/acc': 0.487111563932756, 'demo_condon_steps': 3000, 'few_shot_type': 'prompt', 'model_name_or_path': 'roberta-large', 'gradient_accumulation_steps': 1, 'prompt_learning_rate': 0.001, 'soft_label': 0, 'meta_train_batch_size': 4, 'un_train_batch_size': 4, 'seed': 87, 'prompt_length': 20, 'prompt_encoder_type': 'mlp', 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "args_list = ['mnli-mm_test_eval_mnli-mm/acc', 'mnli_test_eval_mnli/acc',  'demo_condon_steps',\n",
    "             'few_shot_type', 'model_name_or_path', 'gradient_accumulation_steps',  'prompt_learning_rate', 'soft_label',\n",
    "             'meta_train_batch_size', 'un_train_batch_size', 'seed', 'prompt_length', 'prompt_encoder_type', 'learning_rate']\n",
    "\n",
    "task = 'con_prompt_condensen_learning_rate'\n",
    "experiment_path = '/home/t-yaqingwang/azure_storage/projects/few_shot/'\n",
    "path = os.path.join(experiment_path, task)\n",
    "result_path = os.path.join(path, 'pt-results')\n",
    "result_list = []\n",
    "print(len(os.listdir(result_path)))\n",
    "for file_name in os.listdir(result_path):\n",
    "    #args_dict = get_args(file_name) \n",
    "    \n",
    "    eval_result = os.path.join(result_path, file_name)\n",
    "  \n",
    "    try:\n",
    "        args_dict = get_log(eval_result, args_list)\n",
    "        print(args_dict)\n",
    "        result_list.append(args_dict)\n",
    "    except:\n",
    "        continue\n",
    "result_frame = pd.DataFrame(result_list)\n",
    "# path = os.path'/pt-results/few_shot-cf6f4f93-roberta-large-meta-st-SEARCH-search_roberta-large-meta-st-SEARCH_Task_MNLI_roberta-large_0_seed_100_6_1-c49934ef/training_args.bin'\n",
    "# torch.load(path, map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83685cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5397080000000001"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(60 * 1028 + 1024*1024*2)/ (400*1e6) *100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e96feb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.158832"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(60 * 1028 + 1024*1024*2) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1779bb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cd8c084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000*1000 * 2 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
